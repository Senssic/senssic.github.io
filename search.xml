<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[java并发编程]]></title>
    <url>%2F2018%2F09%2F15%2Fsenssic.github.io%2Fjava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[并发编程的挑战上下文切换​ CPU会给每个线程分配时间片用于分配给各个线程执行和占用资源,所以在多线程执行的情况下需要对执行上下文不停切换,会消耗CPU资源,所以在某些特定情况下单线程会比多线程消耗时间少。我们要尽可能的减少上下文切换。 无锁并发编程；多线程的锁竞争会引起上下文切换,处理数据时尽量避免使用锁。例如hash取模,CAS算法等。 使用最少线程；避免创建不需要的线程,不然会导致大量线程等待。 协程；单线程实现多任务调度,并支持多个任务间切换,而避免发生上下文切换。 死锁​ 锁在多线程编程中处理共享资源有很大的作用,但是在使用锁的时候极有可能在多线程环境中发生死锁,从而导致系统不可用,所以我们应避免死锁的发生,避免死锁的基本方法和注意点。 避免一个线程同时获取多个锁,线程获取多个锁资源等会导致资源处理复杂且容易与其他线程发生资源互等待 避免一个线程在锁内同时占用多个资源,尽量保证每个锁只占用一个资源。 使用定时锁或超时锁,这样当获取锁超时会自动退出锁等待释放资源。 对于数据库锁,加锁和解锁必须在一个数据库链接里,否则会出现解锁失败的情况。 资源限制​ 资源限制是指在进行并发编程时,程序的执行速度受限于计算机硬件资源或软件资源。突破资源限制方式 硬件解决方式,可以使用很多廉价的硬件组合编程集群 软件解决的方式,可以使资源进行并发的执行提高效率 java并发机制的底层实现volatile关键字​ Java编程语言允许线程访问共享变量，为了 确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获得这个变量,java内存模型确保所有线程看到这个变量的值是一致的。 ​ volatile实现原理是通过JVM在volatile变量进行写操作后JVM会向处理器发送一条lock的前缀指令,CPU指令lock指令在多核处理器会按照如下方式执行。 将当前处理器缓存行的数据写回到系统内存。 写回内存的操作会使在其他CPU内缓存了该内存地址的数据无效。(CPU缓存一致性,每个处理器探测到中线上传播的数据来检查自己缓存的值是否过期,发现自己缓存行对应的内存地址呗修改,就会将当期处理器的缓存行设置成无效状态,当处理器对这个数据进行修改操作的时候,会重新重系统内存中把数据读到处理器缓存里) synchronized关键字​ synchronized是较少进入java进行多线程同步锁处理的关键字,在JDK1.6之前直接通过锁对象实现,获取和释放锁消耗代价都比较大,之后引用了偏向锁,轻量级锁等,其性能有较大的提升。 ​ java每个对象都可以作为锁对象,synchronized对不同的地方使用有不同的锁对象。 对于普通同步方法，锁是当前实例对象。 对于静态同步方法，锁是当前类的Class对象。 对于同步方法块，锁是Synchonized括号里配置的对象。 synchronized关键字的方法和代码同步是通过Monitor对象实现的。对于代码块的同步是编译器将monitorenter插入到同步代码块开始的位置,而monitorexit插入到方法结束和异常处。JVM保证每个monitorenter必须有一个对应的monitorexit,任何synchronized锁对象都有一个monitor与之关联,线程通过对monitor对象的持有进行互斥,使用monitorenter和monitorexit进行锁的获取和释放。 原子操作的实现​ 原子操作意为不可被中断的一个或一系列操作,一般处理器是通过对缓存和总线加锁的方式实现多处理器之间的原子操作。 通过总线锁保证原子性 通过处理器提供的LOCK#信号,当处理器在总线上输出此信号,其他处理器的请求将被阻塞,该处理器可以独占共享内存。 使用缓存锁保证原子性 一般原子操作我们只需要保证对某个地址的操作是原子性的即可,但是总线锁吧CPU和内存之间的通信锁定了,其他处理器不能操作其他内存数据,开销大。使用缓存锁是如果内区域被缓存在外处理器的缓存行中,并且在lock操作期间被锁定,当执行行锁操作回写内存时不是声明LOCK#信号,而是修改内部内存地址,使用缓存一致性保证原子性。 java实现原子操作 使用循环CAS实现原子操作;利用处理器提供的CMPXCHG指令实现,循环进行CAS操作直到成功为止。CAS能基本保证java的原子操作,但是也会有很多缺点 ABA问题 循环时间长开销大 只能保证一个共享变量的原子操作 使用锁机制实现原子同步;只有获得锁的线程才能够操作锁定的内存区域。JVM锁机制有偏向锁,轻量级锁和互斥锁等。除了偏向锁,JVM实现锁的方式都用了循环 CAS,即当一个线程想进入同步块的时候使用循环CAS的方式来获取锁,当它退出同步块的时候使用循环CAS释放锁。 java内存模型 ​ 在并发编程中,线程之间通讯和线程之间的同步是关键问题。 ​ 线程间的通讯一般使用共享内存和消息传递。在共享内存的并发模型中,通过写-读内存中的公共状态进行隐式通讯。在消息传递的并发模型里,线程之间没有内存公共状态,必须通过显式发送消息进行通讯。 ​ 线程同步是指程序中不同线程之间操作发生相对顺序控制机制。在共享内存中,同步是显式进行的,必须指定摸个方法或代码段在线程之间互斥。在消息传递模型中,同步是隐式进行的,因为发送必须在消息的接收之前。 ​ java的并发使用的共享内存模型,所以线程通讯总是隐式进行的,而同步需要显式指定需要互斥的方法或者代码段。 java内存模型的抽象结构​ java所有实例域,静态域,和数组都存储在堆内存中,线程之间共享。而局部变量,方法定义参数,异常处理器参数不会再线程之间共享,不会有内存可见性问题。 ​ java线程之间的共享变量存储在主内存中,每个线程都有一个私有的本地内存,内存内存存储该线程读/写共享变量的副本。所以A线程和B线程如故需要通讯,需要经历类似如下流程,A线程把本地内存副本共享变量A1刷新到主内存中,线程B线程到主内存中去读线程A之前更新过的共享变量。 ​ JMM控制一个线程对共享变量的写入何时对另一个线程可见,JMM通过控制住内存与每个线程的本地内存之间的交互,为java程序员提供内存可见性保证。 指令序列的重排序​ 在程序执行时,为了提高性能,编译器和处理器有时会对执行做重排序。一般分为编译器优化重排序,指令执行重排序,内存系统重排序。其中指令和内存重排序属于处理器重排序,编译器优化属于编译器重排序。JMM对于编译器重排序使用禁止特定类型的编译器重排序,对于处理器重排序使用插入特定类型的内存屏障禁止特定类型的处理器重排序来为程序员提供一致性内存可见的保证。 内存屏障 现在处理器使用写缓冲区临时保存箱内存写入的数据,写缓冲区可以保证指令流水线持续执行,避免由于处理器停顿下来等待向内存写入数据而产生的延迟。可以批处理的方式刷新写缓冲区,以及合并写缓冲区对同一内存的多次写,减少对内存总线的占用。每个处理器上的写缓冲区仅对它所在的处理器可见。 为了保证内存可见性,java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。JMM把内存屏障指令分为4类。 happens-before 在JMM中,如果一 个操作执行的结果需要对另一个操作可见,那么这两个操作之间必须要存在happens-before关系.这里提到的两个操作既可以是在一个线程之内,也可以是在不同线程之间。一般主要的happens-befor规则有以下几种: 程序顺序规则;一个线程中的每个操作,happens-before于该线程中的任意后续操作。 监视器锁规则;对一个锁的解锁,happens-before于随后对这个锁的加锁。 volatile变量规则;对一个volatile域的写,happens-before于任意后续对这个volatile域的读。 传递性;如果A happens-before B,且B happens-before C,那么A happens-before C。 start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的 ThreadB.start()操作happens-before于线程B中的任意操作。 join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作 happens-before于线程A从ThreadB.join()操作成功返回。 happens-before规则简单易懂,避免了程序员为了理解JMM提供的内存可见性保证而去学习复杂的重排序规则以及这些规则的具体实现方法 JMM的内存可见性保证 通过对内存屏障以及happens-before的了解,JMM为程序员提供了JVM的内存可见性保证,具体可以分为如下三种: 1.单线程程序;单线程程序不会出现内存可见性问题,编译器、runtime和处理器会共同确保单线程程序的执行结果与该程序在顺序一致性模型中的执行结果相同。 2.正确同步的多线程程序;正确同步的多线程程序的执行将具有顺序一致性(程序的执行 结果与该程序在顺序一致性内存模型中的执行结果相同),JMM通过限 制编译器和处理器的重排序来为程序员提供内存可见性保证。 3.未同步/未正确同步的多线程程序;JMM为它们提供了最小安全性保障:线程执行时读取到的值,要么是之前某个线程写入的值,要么是默认值(0、null、false)。 java并发的基础线程简介线程是操作系统调度的最小单元,在一个进程里可以创建多个线程,这些线程都拥有各自的计数器,堆栈和局部变量等属性,并且能够访问共享的内存变量。处理器在这些线程上高速切换,让用户感觉这些线程在同时执行。 为什么使用多线程​ 多线程在某些特定的条件下并不一定比单线程执行效率高。但是在正确的使用多线程可以显著为程序员和用户带来好处。 更多的处理器核心;随着处理器的核心数越来越多,现代计算机更擅长并行计算,能更大效率的使用计算机处理器。 更快的响应时间;能极大的利用处理器的效率,在宏观下能并行处理多个任务线,给用户更快的响应时间。 更好的编程模型;是开发人员更加专注问题的解决,为问题简历合适的模型,而不是考虑如何将其多线程化。 线程的状态​ 在java线程的生命周期中有6种不同的状态,在给定的时刻线程只能处于其中的一个状态: NEW;初始状态,线程被构建,但是还没有调用start()方法。 RUNNABLE;运行状态,java线程将操作系统中的就绪和运行两种状态笼统的称为”运行中“ BLOCKED;阻塞状态,表示线程阻塞于锁 WAITING;等待状态,表示线程进入等待状态,进入等待状态表示当前线程需要等待其他线程做出一些特定动作(通知或中断) TIME_WAITING;超时等待状态,该状态不同于WAITING,它是可以再指定的时间自行返回的。 TERMINATED;终止状态,表示当前线程已执行完毕 java线程间的通讯 Volatile和synchronized关键字 java支持多线程同时访问一个对象或对象的成员变量,由于每个线程拥有这个变量的拷贝,所以在程序的执行过程中,一个线程锁访问的共享变量不一定是最新的。volatile变量能保证所有线程对变量访问都是最新的。即保证共享变量对所有线程的可见性,但有时我们需要控制方法或代码段的同步,这时候就需要使用synchronized关键字来修饰了,他保证在多线程在同一时刻,只有一个线程处于同步方法或同步块中,即保证了同步块访问的可见性和排他性。 等待/通知机制 一个线程A调用了对象O的wait()方法进入等待状态,另一个线程B调用了对象的notify()或者notifyAll()方法,线程A收到通知后从对象O的wait()方法返回,进而执行后续操作。上述两个线程通过对象O来完成交互,而对象上的wait()和notify()/notifyAll()的关系就如同开关信号,用来完成等待方和通知方之间的交互工作。 1）使用wait()、notify()和notifyAll()时需要先对调用对象加锁。 2）调用wait()方法后，线程状态由RUNNING变为WAITING，并将当前线程放置到对象的 等待队列。 3）notify()或notifyAll()方法调用后，等待线程依旧不会从wait()返回，需要调用notify()或 notifAll()的线程释放锁之后，等待线程才有机会从wait()返回。 4）notify()方法将等待队列中的一个等待线程从等待队列中移到同步队列中，而notifyAll() 方法则是将等待队列中所有的线程全部移到同步队列，被移动的线程状态由WAITING变为 BLOCKED。 5）从wait()方法返回的前提是获得了调用对象的锁。 管道输入/输出流 管道输入/输出流和普通的文件输入/输出流或者网络输入/输出流不同之处在于，它主要 用于线程之间的数据传输，而传输的媒介为内存。 管道输入/输出流主要包括了如下4种具体实现:PipedOutputStream、PipedInputStream、 PipedReader和PipedWriter，前两种面向字节，而后两种面向字符。 java中的锁​ 锁用来控制多个线程访问共享资源的方式,防止其数据或状态出现不可控的变化。 使用volatilejava提供了volatile关键字,在多个处理器中可以立即读到最新的值,即一个线程修改值后另一个线程立即能获取到更新后的值。 使用synchronized为了减少锁获取和释放带来的开销在JSE1.6版本锁的状态达到了四个,级别从低到高依次为 无锁状态&lt;偏向锁状态&lt;轻量级锁状态&lt;重量级锁状态随着竞争激烈程度依次递增。synchronize不支持锁的降级,这种策略是为了提高获取和释放锁的效率。 Lock接口​ Lock接口的实现基本都是 通过聚合了一个同步器(AQS)的子类来完成线程访问控制的。 队列同步器(AQS的介绍)​ AQS是JDK下提供的一套用于实现基于FIFO等待队列的阻塞锁或相关的同步组件的一个同步框架。实现原理是内部通过一个volatile的int类型成功变量表示同步状态,通过CAS进行原子的状态设置,内置的FIFO双向队列来完成获取锁线程的排队工作。 getState():获取当前同步状态。 setState(int newState):设置当前同步状态。 compareAndSetState(int expect,int update):使用CAS设置当前状态，该方法能够保证状态 设置的原子性。 重入锁​ 就是支持重进入的锁,它表示该锁能够支持一个线程对资源的重复加锁。除此之外,该锁的还支持获取锁时的公平和非公平性选择。在线程获取到锁之后能够再次获取该锁而不会被锁阻塞,重入锁实现原理: 1）线程再次获取锁;锁需要去识别获取锁的线程是否为当前占据锁的线程,如果是,则再 次成功获取。 2）锁的最终释放;线程重复n次获取了锁,随后在第n次释放该锁后,其他线程能够获取到该锁。锁的最终释放要求锁对于获取进行计数自增,计数表示当前锁被重复获取的次数,而锁被释放时,计数自减,当计数等于0时表示锁已经成功释放。 synchronized和reentrantLock等都是可重入锁。 公平与非公平锁的区别,公平性针对获取锁而言,如果一个锁是公平的,那么锁的获取顺序就应该符合请求的绝对时间顺序。 读写锁(ReentrantReadWriteLock)​ 读写锁在同一时刻可以允许多个读线程访问,但是在写线程访问时,所有的读线程和其他写线程均被阻塞。读写锁维护了一对锁,一个读锁和一个写锁,通过分离读锁和写锁,使得并发性相比一般的排他锁有了很大提升。 写锁的获取与释放 写锁是一个支持重进入的排它锁,如果当前线程已经获取了写锁,则增加写状态。如果当 前线程在获取写锁时,读锁已经被获取(读状态不为0)或者该线程不是已经获取写锁的线程, 则当前线程进入等待状态。 读锁的获取与释放 读锁是一个支持重进入的共享锁,它能够被多个线程同时获取,在没有其他写线程访问(或者写状态为0)时，读锁总会被成功地获取,而所做的也只是(线程安全的)增加读状态。如 果当前线程已经获取了读锁,则增加读状态。如果当前线程在获取读锁时,写锁已被其他线程 获取,则进入等待状态。 锁降级 锁降级指的是写锁降级成为读锁。如果当前线程拥有写锁,然后将其释放,最后再获取读锁,这种分段完成的过程不能称之为锁降级。锁降级是指把持住(当前拥有的)写锁,再获取到读锁,随后释放(先前拥有的)写锁的过程。 ​ RentrantReadWriteLock不支持锁升级(把持读锁、获取写锁,最后释放读锁的过程)。目的也是保证数据可见性,如果读锁已被多个线程获取,其中任意线程成功获取了写锁并更新了数据,则其更新对其他获取到读锁的线程是不可见的。 LockSupport工具​ 当需要阻塞或唤醒一个线程的时候,都会使用LockSupport工具类来完成相应 工作。LockSupport定义了一组的公共静态方法,这些方法提供了最基本的线程阻塞和唤醒功 能,而LockSupport也成为构建同步组件的基础工具。 Condition接口​ 任意一个Java对象,都拥有一组监视器方法(定义在java.lang.Object上),主要包括wait()、 wait(long timeout)、notify()以及notifyAll()方法,这些方法与synchronized同步关键字配合,可以 实现等待/通知模式。Condition接口也提供了类似Object的监视器方法,与Lock配合可以实现等 待/通知模式。 java并发容器和框架ConcurrentHashMap​ concurrentHashMap能在即保证并发环境下的安全又能保证高效的读写,其原理是将数据分成一段一段地存 储,然后给每一段数据配一把锁,当一个线程占用锁访问其中一个段数据的时候,其他段的数据也能被其他线程访问。 ​ ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可重 入锁(ReentrantLock)在ConcurrentHashMap里扮演锁的角色;HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组。Segment的结构和HashMap类似,是一种 数组和链表结构。一个Segment里包含一个HashEntry数组,每个HashEntry是一个链表结构的元素,每个Segment守护着一个HashEntry数组里的元素,当对HashEntry数组的数据进行修改时,必须首先获得与它对应的Segment锁。 ConcurrentLinkedQueue​ ConcurrentLinkedQueue是一个基于链接节点的无界线程安全队列,它采用先进先出的规则对节点进行排序,当我们添加一个元素的时候,它会添加到队列的尾部;当我们获取一个元素时,它会返回队列头部的元素。 阻塞队列​ 阻塞队列(BlockingQueue)是一个支持两个附加操作的队列。这两个附加的操作支持阻塞的插入和移除方法。 支持阻塞的插入方法:意思是当队列满时,队列会阻塞插入元素的线程,直到队列不 满。 支持阻塞的移除方法:意思是在队列为空时,获取元素的线程会等待队列变为非空。 阻塞队列常用于生产者和消费者的场景,生产者是向队列里添加元素的线程,消费者是从队列里取元素的线程。阻塞队列就是生产者用来存放元素、消费者用来获取元素的容器。 JDK 7提供了7个阻塞队列 ArrayBlockingQueue:一个由数组结构组成的有界阻塞队列。 LinkedBlockingQueue:一个由链表结构组成的有界阻塞队列。 PriorityBlockingQueue:一个支持优先级排序的无界阻塞队列。 DelayQueue:一个使用优先级队列实现的无界阻塞队列。 SynchronousQueue:一个不存储元素的阻塞队列。 LinkedTransferQueue:一个由链表结构组成的无界阻塞队列。 LinkedBlockingDeque:一个由链表结构组成的双向阻塞队列。 阻塞队列是使用通知模式实现。所谓通知模式,就是当生产者往满的队列里添加元素时会阻塞住生产者,当消费者消费了一个队列中的元素后,会通知生产者当前队列可用。 Fork/Join框架​ Fork/Join框架是Java 7提供的一个用于并行执行任务的框架,是一个把大任务分割成若干个小任务,最终汇总每个小任务结果后得到大任务结果的框架。 java中的原子操作类AtomicBoolean：原子更新布尔类型AtomicInteger：原子更新整型AtomicLong：原子更新长整型AtomicIntegerArray：原子更新整型数组里的元素AtomicLongArray：原子更新长整型数组里的元素AtomicReferenceArray：原子更新引用类型数组里的元素AtomicIntegerArray类主要是提供原子的方式更新数组里的整型AtomicReference：原子更新引用类型AtomicReferenceFieldUpdater：原子更新引用类型里的字段AtomicMarkableReference：原子更新带有标记位的引用类型AtomicIntegerFieldUpdater：原子更新整型的字段的更新器AtomicLongFieldUpdater：原子更新长整型字段的更新器AtomicStampedReference：原子更新带有版本号的引用类型 java中的并发工具类多线程完成的CountDownLatch​ CountDownLatch允许一个或多个线程等待其他线程完成操作。 同步屏障CyclicBarrier​ CyclicBarrier的字面意思是可循环使用(Cyclic)的屏障(Barrier)它要做的事情是,让一 组线程到达一个屏障(也可以叫同步点)时被阻塞,直到最后一个线程到达屏障时,屏障才会 开门,所有被屏障拦截的线程才会继续运行。 ​ CountDownLatch的计数器只能使用一次,而CyclicBarrier的计数器可以使用reset()方法重置。所以CyclicBarrier能处理更为复杂的业务场景。例如,如果计算发生错误,可以重置计数 器,并让线程重新执行一次。 控制并发线程数的Semaphore​ Semaphore（信号量）是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以 保证合理的使用公共资源。 线程交换数据的Exchanger​ Exchanger(交换者)是一个用于线程间协作的工具类。Exchanger用于进行线程间的数据交 换。它提供一个同步点,在这个同步点,两个线程可以交换彼此的数据。这两个线程通过 exchange方法交换数据,如果第一个线程先执行exchange()方法,它会一直等待第二个线程也 执行exchange方法,当两个线程都到达同步点时,这两个线程就可以交换数据,将本线程生产出来的数据传递给对方。 线程池线程池的处理流程如下 线程池判断核心线程池里的线程是否都在执行任务。如果不是，则创建一个新的工作 线程来执行任务。如果核心线程池里的线程都在执行任务，则进入下个流程。 线程池判断工作队列是否已经满。如果工作队列没有满，则将新提交的任务存储在这 个工作队列里。如果工作队列满了，则进入下个流程。 线程池判断线程池的线程是否都处于工作状态。如果没有，则创建一个新的工作线程 来执行任务。如果已经满了，则交给饱和策略来处理这个任务。 Executor框架Executor框架的主要接口 Executor是一个接口，它是Executor框架的基础，它将任务的提交与任务的执行分离开 ThreadPoolExecutor是线程池的核心实现类，用来执行被提交的任务。 ScheduledThreadPoolExecutor是一个实现类，可以在给定的延迟后运行命令，或者定期执 行命令ScheduledThreadPoolExecutor比Timer更灵活，功能更强大。 Future接口和实现Future接口的FutureTask类，代表异步计算的结果。 Runnable接口和Callable接口的实现类，都可以被ThreadPoolExecutor或ScheduledThreadPoolExecutor执行。 java并发编程]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[哈希表_散列表]]></title>
    <url>%2F2018%2F08%2F20%2Fsenssic.github.io%2F%E5%93%88%E5%B8%8C%E8%A1%A8-%E6%95%A3%E5%88%97%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[哈希表介绍哈希表(也称散列表,hash table),是根据键值直接访问其对应的数据存储位置的一种数据结构。若使用数组或者链表来存储元素则在比较某个元素时,数组或链表需要循环进行比较,而通过哈希表只需要计算出对应的哈希位置取出对应的值进行比较或判断在否。 其有以下几种特性: 若关键字为k,则其值存放在f(k)[散列函数]的存储位置上。 对不同的关键字可能得到同一散列地址，即k1≠k2而f(k1)=f(k2),这种现象称为冲突。 若对于关键字集合中的任一个关键字，经散列函数映象到地址集合中任何一个地址的概率是相等的，则称此类散列函数为均匀散列函数,以便减少冲突。 构造哈希函数的方法一个好的哈希函数能够提升查找效率减少哈希地址冲突带来的额外处理开销,常用的哈希函数有以下几种: 直接地址 H(key) = key 或 H(key) = a*key + b，其中a和b为常数 平方取中法 先计算出关键字值的平方，然后取平方值中间几位作为散列地址。假如有以下关键字序列{421，423，436}，平方之后的结果为{177241，178929，190096}，那么可以取中间的两位数{72，89，00}作为Hash地址。 折叠法 将关键字拆分成几部分，然后将这几部分组合在一起，以特定的方式进行转化形成Hash地址。假如知道图书的ISBN号为8903-241-23，可以将address(key)=89+03+24+12+3作为Hash地址。 除留取余法 如果知道Hash表的最大长度为m，可以取不大于m的最大质数p，然后对关键字进行取余运算，address(key)=key%p。在这里p的选取非常关键，p选择的好的话，能够最大程度地减少冲突，p一般取不大于m的最大质数。当关键字是整数时候比较好的避免冲突。 数字分析法 假设关键字是以r为基的数，并且哈希表中可能出现的关键字都是事先知道的，则可取关键字的若干数位组成哈希地址。 随机数法 选择一个随机函数，把关键字的随机函数值作为它的哈希值,通常当关键字的长度不等时用这种方法。当关键字是小数的时候比较好的避免地址冲突。 解决哈希冲突基于哈希的数据结构有着接近常量的时间即0(1)[基于数据]的时间复杂度,对于大量数据的查询效率极为高效。哈希的查找效率因数基本和哈希函数是否均匀,处理冲突的方法,哈希表的加载因子有关。 开放地址法 当发生冲突时,从当前位置向后按某种策略遍历哈希表。当发现可用的空间的时候,则插入元素。开放地址有一次探测(hs=(h(key)+i) ％ m,0 ≤ i ≤ m-1)、二次探测(hi=(h(key)+i*i) ％ m，0 ≤ i ≤ m-1)和双重哈希(hs=(h(key)+i*h1(key)) ％ m,0 ≤ i ≤ m-1)。 一次探测 探查时从地址 d 开始，首先探查 T[d]，然后依次探查 T[d+1]，…，直到 T[m-1]，此后又循环到 T[0]，T[1]，…，直到探查到 有空余地址 或者到 T[d-1]为止。 二次探测 探查时从地址 d 开始，首先探查 T[d]，然后依次探查 T[d+1^2]，T[d+2^2]，T[d+3^2],…，等，直到探查到 有空余地址 或者到 T[d-1]为止。缺点是无法探查到整个散列空间。 双重哈希 探查时从地址 d 开始，首先探查 T[d]，然后依次探查 T[d+h1(d)], T[d + 2*h1(d)]，…，等。该方法使用了两个散列函数 h(key) 和 h1(key)，故也称为双散列函数探查法。定义 h1(key) 的方法较多，但无论采用什么方法定义，都必须使 h1(key) 的值和 m 互素，才能使发生冲突的同义词地址均匀地分布在整个表中，否则可能造成同义词地址的循环计算。该方法是开放定址法中最好的方法之一。 开放定址在解决当前冲突的情况下同时可能会导致新的冲突，而开链不会有这种问题。 链地址法(又开链法) 开链的思想是哈希表中的每个元素都是一个类似链表或者其他数据结构的 head。当出现冲突时，我们就在链表后面添加元素。这也就意味着，如果某一个位置冲突过多的话，插入的时间复杂段将退化为 O(N)。 开链相比于开放定址局部性较差，在程序运行过程中可能引起操作系统的缺页中断，从而导致系统颠簸。 ​ 再哈希法 Hi=RH1（key） i=1，2，…，k 当哈希地址Hi=RH1（key）发生冲突时，再计算Hi=RH2（key）……，直到冲突不再产生。这种方法不易产生聚集，但增加了计算时间。很多语言或者工具包再哈希的内部实现是使用了两个数组，其中一个作为备用。如果当前哈希表的负载因子（元素个数/哈希表容量大小）过大或者过小时，就将数据切换到备用数组里。 建立一个公共溢出区 假设哈希函数的值域为[0,m-1],则设向量HashTable[0..m-1]为基本表，另外设立存储空间向量OverTable[0..v]为溢出表用以存储发生冲突的记录。，凡是和基本表发生冲突的元素，一律填入溢出表。 一次性哈希算法在分布式的系统中我们希望能把数据进行分布式存储,这样能极大的提升整体性能,但是需要保证相同的缓存key请求总是能被负载到同一台机器。我们可以使用简单的hash算法,对于每次访问，可以按如下算法计算其哈希值： h = Hash(key) % n 字符串到正整数的哈希映射函数。这样，如果我们将服务器数量n分别编号为0、1、2，那么就可以根据上式和key计算出服务器编号h，然后去访问。 这样做虽然能解决问题,但是存在扩展性不好的缺点,如果增加或删除一台机器势必需要哈希值得重新计算导致大量的key会被重定位到不同的服务器从而造成大量的缓存不命中。 ​ 简单来说，一致性哈希将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0 - 232-1（即哈希值是一个32位无符号整形）,整个空间按顺时针方向组织。0和232-1在零点中方向重合。将数据key使用相同的函数H计算出哈希值h，通根据h确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。一致性哈希算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。 虚拟节点​ 一致性哈希算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜问题。使得大量数据会访问到同一台机器上,为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。数据定位算法不变，只是多了一步虚拟节点到实际节点的映射。 哈希表的实现(1) 一次性了解哈希相关概念：哈希 哈希函数 冲突解决 哈希表 聊一聊哈希表 [一致性哈希算法及其在分布式系统中的应用]]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>哈希表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式锁的常见实现]]></title>
    <url>%2F2018%2F08%2F17%2Fsenssic.github.io%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%B8%B8%E8%A7%81%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[现在的系统部署大部分都是分布式部署的方式,对于需要使用锁的场景不能再通过使用单纯的Java Api实现。产生了基于数据库，缓存(redis,memcached,tair),和zookeeper实现的分布式锁。 对于分布式锁我们希望的理想锁的表现 在分布式环境中保证同一个临界区在同一时间只在一台机器上执行。 这把分布式锁是可重入锁[避免死锁] 可以根据业务需要变成阻塞锁 获取和释放锁性能高 基于数据库实现分布式锁基于唯一索引实现1.创建一张带唯一索引的表 12345678CREATE TABLE `blockLock` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键', `block_name` varchar(64) NOT NULL DEFAULT '' COMMENT '锁定的块名称', `desc` varchar(1024) NOT NULL DEFAULT '备注信息', `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '保存数据时间，自动生成', PRIMARY KEY (`id`), UNIQUE KEY `uidx_method_name` (`block_name `) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8; 2.在想要添加锁的块代码之前插入数据,由于block_name做了唯一索引,同样块名称的操作只能有一个成功。 1insert into methodLock(method_name,desc) values (‘block_name’,‘the same block_name commit’); 3.临界代码执行完毕需要释放锁,此时只需要将block_name这条数据删除或更新即可 1delete from methodLock where method_name ='block_name' 优点: 实现方便,便于理解 缺点: 如果数据库是单点,则可靠性不能保证 没有失效时间,不会自动释放锁,一旦解锁失败会导致其他线程无法再获取到锁。 这把锁只能是非阻塞的,插入失败直接报错返回,无法自动阻塞再次尝试获取锁 这把锁是非重入锁,线程获取锁后无法再次获取此锁,因为数据库已存在唯一索引值。 对于基于数据库的锁获取和释放锁的开销相对比较大 基于数据库的排他锁在mySql的InnoDB引擎的查询语句后增加for update,这样在查询的过程中数据库会增加排他锁【注意:如果想使用查询参数要建立唯一索引,由于InnoDB 预设是Row-Level Lock，所以只有「明确」的指定主键，MySQL 才会执行Row lock (只锁住被选取的数据) ，否则MySQL 将会执行Table Lock (将整个数据表单给锁住】。 添加锁代码1234567891011121314151617181920public boolean lock()&#123; Long timeout=10000； long futureTime = System.currentTimeMillis() + timeOuts; connection.setAutoCommit(false) while(true)&#123; try&#123; result = select * from blockLock where block_name=xxx for update; if(result==null)&#123; return true; &#125; &#125;catch(Exception e)&#123; &#125; sleep(1000); if(futureTime&lt;System.currentTimeMillis())&#123; break; &#125; &#125; return false;&#125; 释放锁代码123public void unlock()&#123; connection.commit();&#125; 优点: 阻塞锁,for update语句会一直等待直到执行成功后返回结果 自动释放锁,当数据库连接断开时候会自动释放锁 缺点: 如果数据库是单点,则可靠性不能保证 对于基于数据库的锁获取和释放锁的开销相对比较大 使用不当容易变成表级锁,容易影响业务 利用事务进行加锁的时候会导致很多连接不能及时释放,导致连接池爆满 基于缓存实现分布式锁相较于数据库实现的分布式锁,基于缓存实现的分布式锁更加高效，且有很多成熟的方案,redis,memcached以及tair等都有很好的支持。 下面是基于redis实现的分布式锁 添加锁代码123456789101112private static final String LOCK_SUCCESS = "OK";private static final String SET_IF_NOT_EXIST = "NX";private static final String SET_WITH_EXPIRE_TIME = "PX";public static boolean tryGetDistributedLock(Jedis jedis, String lockKey, String requestId, int expireTime) &#123; String result = jedis.set(lockKey, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime); if (LOCK_SUCCESS.equals(result)) &#123; return true; &#125; return false;&#125; 第一个为key，我们使用key来当锁，因为key是唯一的。 第二个为value，我们传的是requestId，很多童鞋可能不明白，有key作为锁不就够了吗，为什么还要用到value？原因就是我们在上面讲到可靠性时，分布式锁要满足第四个条件解铃还须系铃人，通过给value赋值为requestId，我们就知道这把锁是哪个请求加的了，在解锁的时候就可以有依据。requestId可以使用UUID.randomUUID().toString()方法生成。 第三个为nxxx，这个参数我们填的是NX，意思是SET IF NOT EXIST，即当key不存在时，我们进行set操作；若key已经存在，则不做任何操作； 第四个为expx，这个参数我们传的是PX，意思是我们要给这个key加一个过期的设置，具体时间由第五个参数决定。 第五个为time，与第四个参数相呼应，代表key的过期时间。 ##释放锁代码: 12345678910111213private static final Long RELEASE_SUCCESS = 1L;public static boolean releaseDistributedLock(Jedis jedis, String lockKey, String requestId) &#123; //就是在eval命令执行Lua代码的时候，Lua代码将被当成一个命令去执行，并且直到eval命令执行完成，Redis才会执行其他命令。 String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end"; Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId)); if (RELEASE_SUCCESS.equals(result)) &#123; return true; &#125; return false; &#125; 首先获取锁对应的value值，检查是否与requestId相等，如果相等则删除锁（解锁）。使用Lua语言来确保上述操作是原子性。 优点： 缓存服务可以做集群提高可用性 获取锁和释放锁效率高 可以设置超时时间,超时会自动释放锁 缺点: 这是把非阻塞锁,无论成功失败会直接返回 这是把非重入锁,当一个线程获取锁后在释放锁前此线程无法再次获得该锁 失效时间平衡设置比较困难(时间短,会产生并发问题,时间长,会导致浪费的资源等待) 基于zookeeper实现分布式锁zookeeper会为客户端加锁的请求建立唯一一个瞬时有序节点,判断获取锁只需要判断此节点是否为此有序节点中序号最小的一个。当释放锁时候,只需要将这个瞬时节点删除可以。 使用curator客户端操作zookeeper 123456789101112131415161718public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; try &#123; return interProcessMutex.acquire(timeout, unit); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return true;&#125;public boolean unlock() &#123; try &#123; interProcessMutex.release(); &#125; catch (Throwable e) &#123; log.error(e.getMessage(), e); &#125; finally &#123; executorService.schedule(new Cleaner(client, path), delayTimeForClean, TimeUnit.MILLISECONDS); &#125; return true;&#125; 优点: 锁释放,当客户获取锁后突然挂掉(session连接断开),临时节点会自动删除。其他客户端可以再次获取锁 可实现阻塞锁,客户端通过在zk中创建有顺序节点,并且绑定监听,如果节点变化zk会通知客户端,客户端检查自己创建的节点是不是当前所有节点中序号最小的从而判断是否获取到锁。 可重入,客户端在创建节点时,zk会把当前客户端主机信息和线程信息写到节点中,客户端线程再次想获取锁时候和当前最小节点的数据对比一下就可以了。如果信息一样便是已获取到锁。 高可用,zk是集群部署的。 缺点: 由于需要很多判断和信息写入读取,以及分发信息,效率并没有基于缓存的高 有极低的概率会(zk有重试机制只有多次重试仍检测不到客户端心跳就会删除客户端临时节点)导致并发问题,如:当网络抖动失去客户端连接,别的客户端可能会得到分布式锁。 分布式锁的几种实现Redis 分布式锁的正确实现方式（ Java 版 ）]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>锁</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java锁相关]]></title>
    <url>%2F2018%2F08%2F16%2Fsenssic.github.io%2Fjava%E9%94%81%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[在并发系统中常常需要对某些业务资源进行加锁操作，解决一些因并发操作导致的数据不一致,以及读到脏数据问题。 加锁的目的本质上是对资源的一种操作控制,防止其数据或状态出现不可控的变化。 java中对于锁的支持使用volatilejava提供了volatile关键字,在多个处理器中可以立即读到最新的值,即一个线程修改值后另一个线程立即能获取到更新后的值。 在某些适用volatile场景的地方使用volatile控制线程变量可见性会起到很好的效果,虽然volatile不能代替synchronize(因为volatile不能提供原子操作,只是对于多线程的变量可见性),但在适用的场景下要优于synchronize执行成本,因为它不会引起线程上下文的切换和调度。 使用synchronizesynchronize通过锁机制实现同步具体锁对象有三种方式 普通方法的同步,锁是当前实力对象 静态方法的同步,锁是当前类的class对象 对于同步代码块,锁是括号内的对象 synchronize的实现原理synchronize是通过jvm执行Monitor的互斥执行和协作来实现锁的。 互斥:使用synchronize获取的对象锁来进行共享数据线程互斥 协作:通过notify/notifyAll/wait方法同步线程之间的操作 必要条件:每个Object和Class都关联了一个monitor Monitor 的工作机理 线程进入同步方法中。 为了继续执行临界区代码，线程必须获取 Monitor 锁。如果获取锁成功，将成为该监视者对象的拥有者。任一时刻内，监视者对象只属于一个活动线程（The Owner）,对于重入的synchronize关键字monitor会讲进入数自增1,所以synchronize是可重入锁 拥有监视者对象的线程可以调用 wait() 进入等待集合（Wait Set），同时释放监视锁，进入等待状态。 其他线程调用 notify() / notifyAll() 接口唤醒等待集合中的线程，这些等待的线程需要重新获取监视锁后才能执行 wait() 之后的代码。 同步方法执行完毕了，线程退出临界区，并释放监视锁。 synchronize锁机制的优化为了减少锁获取和释放带来的开销在JSE1.6版本锁的状态达到了四个,级别从低到高依次为 无锁状态&lt;偏向锁状态&lt;轻量级锁状态&lt;重量级锁状态随着竞争激烈程度依次递增。synchronize不支持锁的降级,这种策略是为了提高获取和释放锁的效率。 偏向锁-一段代码一直被同一个线程访问,那么该线程自动获取锁,此举为了降低获取锁的代价。 优点:加锁和解锁不需要额外的消耗,和非同步代码比较仅存在纳秒级别的差距。 缺点:一旦出现锁竞争会有撤销锁的消耗。 轻量级锁-当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。 优点:线程不阻塞,提高性能 缺点:如果长时间得不到锁自旋会消耗cpu 重量级锁-当锁是轻量级锁的时候,另一个线程虽然在自旋但不会一直自旋,当自旋到一定次数还没有获取到锁就会进入阻塞该锁膨胀为重量级锁,重量级锁会让其他申请的线程进入阻塞,性能降低。 优点:不会消耗cpu 缺点:线程阻塞,响应时间缓慢。 自旋状态-轻量级锁的具体实现原理,指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。 CAS(compare and swap)和AQS(AbstractQueuedSynchronizer)CAS的介绍CAS是一个原子操作,利用了处理器的CMPXCHG指令实现的,CAS操作包括三个操作数,内存位置(V),预期原值(A)和新值(B)。如果内存位置和预期原值相等则处理器会将内存位置更新为新值(B),若反之则不做任何操作。 CAS的优点在于竞争不大的情况下系统开销小,缺点是只能保证一个变量的原子操作,以及不能避免ABA问题(如果另一个线程修改V值假设原来是A，先修改成B，再修改回成A,当前线程的CAS操作无法分辨当前V值是否发生过变化)。 AQS的介绍AQS是JDK下提供的一套用于实现基于FIFO等待队列的阻塞锁或相关的同步组件的一个同步框架。 AQS的实现原理内部通过一个volatile的int类型成功变量表示同步状态 123456789101112131415161718192021222324252627282930/** * The synchronization state. * 同步状态 */private volatile int state;/** * Returns the current value of synchronization state. * 获取当前同步状态 */protected final int getState() &#123; return state;&#125;/** * Sets the value of synchronization state. * 设置当前同步状态 */protected final void setState(int newState) &#123; state = newState;&#125;/** * Atomically sets synchronization state to the given updated * value if the current state value equals the expected value. * 使用CAS设置当前状态,该方法能保证状态设置的原子性 */protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125; 内置的FIFO双向队列来完成获取锁线程的排队工作 同步器包含两个节点类型的应用，一个指向头节点，一个指向尾节点，未获取到锁的线程会创建节点线程安全（compareAndSetTail）的加入队列尾部。同步队列遵循FIFO，首节点是获取同步状态成功的节点。 未获取到锁的线程将创建一个节点，设置到尾节点 首节点的线程在释放锁时，将会唤醒后继节点。而后继节点将会在获取锁成功时将自己设置为首节点 独占式和共享式获取锁独享锁-指该锁一次只能被一个线程所持有共享锁-指该锁可被多个线程所持有 独占锁(ReentrantLock) ​ 每个节点自旋观察自己的前一节点是不是Header节点，如果是，就去尝试获取锁 ​ 独占式锁获取流程 ​ 共享锁(CountDownLatch) ​ 共享式与独占式的区别 ​ 共享锁获取流程 Java中的锁 (原理、锁优化、CAS、AQS)Java中的锁分类]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你好,世界]]></title>
    <url>%2F2018%2F08%2F09%2Fsenssic.github.io%2F%E4%BD%A0%E5%A5%BD%2C%E4%B8%96%E7%95%8C%2F</url>
    <content type="text"><![CDATA[你好,世界 你好,世界！不要在生活中迷失！ –2018年08月07日01:38:41]]></content>
      <categories>
        <category>生活百味</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>杂项</tag>
        <tag>感悟</tag>
      </tags>
  </entry>
</search>
