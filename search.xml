<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[docker的maven插件使用]]></title>
    <url>%2F2019%2F01%2F06%2Fsenssic.github.io%2F201901%2Fdocker%E7%9A%84maven%E6%8F%92%E4%BB%B6%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[搭建docker私有仓库创建私有仓库 拉取仓库镜像 docker pull registry 启动仓库镜像 docker run ‐di ‐‐name=registry ‐p 5000:5000 registry 修改daemon.json,让docker信任私有仓库地址 vi /etc/docker/daemon.json 添加 {&quot;insecure‐registries&quot;:[&quot;127.0.0.1:5000&quot;]} 重启docker服务 systemctl restart docker 镜像上传到私有仓库为了验证私有仓库搭建以及能正常上传到私有仓库,新建tag并尝试push镜像 标记此镜像为私有仓库的镜像 docker tag java:8 127.0.0.1:5000/jdk1.8 注意:java:8为本身已经存在的镜像 再次启动私服容器 docker start registry 上传标记的镜像 docker push 127.0.0.1:5000/jdk1.8 从私有仓库拉取pull的时候记得带”主机IP:5000”,不然还是去Docker hub上下载而不是私有仓库下载 docker pull 127.0.0.1:5000/xxx/xxx Docker 私有仓库安装配置 (Registry v2) docker的maven插件使用生成TLS认证远程访问 Docker需要生成三种证书类型: CA 证书用来生成客户端和服务端证书 远端Docker使用的客户端生疏 服务端使用的Docker daemon证书 服务端配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263# 生成 CA 私钥$ openssl genrsa -aes256 -out ca-key.pem 4096# 需要输入两次密码(自定义)# 生成 CA 公钥$ openssl req -new -x509 -days 365 -key ca-key.pem -sha256 -out ca.pem# 输入上一步中设置的密码，然后需要填写一些信息# 下面是服务器证书生成# 生成服务器私钥$ openssl genrsa -out server-key.pem 4096# 用私钥生成证书请求文件$ openssl req -subj &quot;/CN=localhost&quot; -sha256 -new -key server-key.pem -out server.csr$ echo subjectAltName = DNS:localhost,DNS:www.khs1994.com,DNS:tencent,IP:192.168.199.100,IP:192.168.57.110,IP:127.0.0.1 &gt;&gt; extfile.cnf# 允许服务端哪些 IP 或 host 能被客户端连接，下文会进行测试。# DNS 我也不是很理解，这里配置 localhost ，公共 DNS 解析的域名，/etc/hosts 文件中的列表进行测试。$ echo extendedKeyUsage = serverAuth &gt;&gt; extfile.cnf# 用 CA 来签署证书$ openssl x509 -req -days 365 -sha256 -in server.csr -CA ca.pem -CAkey ca-key.pem \ -CAcreateserial -out server-cert.pem -extfile extfile.cnf# 再次输入第一步设置的密码# 下面是客户端证书文件生成# 生成客户端私钥$ openssl genrsa -out key.pem 4096# 用私钥生成证书请求文件 $ openssl req -subj &apos;/CN=client&apos; -new -key key.pem -out client.csr$ echo extendedKeyUsage = clientAuth &gt;&gt; extfile.cnf# 用 CA 来签署证书$ openssl x509 -req -days 365 -sha256 -in client.csr -CA ca.pem -CAkey ca-key.pem \ -CAcreateserial -out cert.pem -extfile extfile.cnf# 再次输入第一步设置的密码# 删除文件，更改文件权限$ rm -v client.csr server.csr$ chmod -v 0400 ca-key.pem key.pem server-key.pem$ chmod -v 0444 ca.pem server-cert.pem cert.pem 把 ca.pem server-cert.pem server-key.pem 三个文件移动到 /etc/docker/ 文件夹中。 在远端配置Docker配置/etc/docker/daemon.json文件如下,注意,镜像地址与本文无关,可不配置 1234567&quot;insecure-registries&quot;:[&quot;127.0.0.1:5000&quot;], &quot;tlsverify&quot;: true, &quot;tlscacert&quot;: &quot;/etc/docker/ca.pem&quot;, &quot;tlscert&quot;: &quot;/etc/docker/server-cert.pem&quot;, &quot;tlskey&quot;: &quot;/etc/docker/server-key.pem&quot;, &quot;hosts&quot;: [&quot;tcp://0.0.0.0:2376&quot;,&quot;unix:///var/run/docker.sock&quot;]&#125; CoreOS 官方文档的方法首先需要修改 /etc/systemd/system/docker-tcp.socket 文件内容 12345ListenStream=2375# 修改为ListenStream=2376 重新启动服务器 1234$ sudo systemctl daemon-reload$ sudo systemctl stop docker$ sudo systemctl restart docker-tcp.socket$ sudo systemctl restart docker 将 ca.pem cert.pem key.pem下载到客户端,放置到~/.docker目录下 运行测试命令 docker –tlsverify -H=tcp://207.246.117.90:2376 info Maven插件自动部署步123456789101112131415161718192021&lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;docker-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.4.13&lt;/version&gt; &lt;configuration&gt; &lt;imageName&gt;127.0.0.1:5000/$&#123;docker.image.prefix&#125;/$&#123;project.artifactId&#125; &lt;/imageName&gt; &lt;baseImage&gt;java:8&lt;/baseImage&gt; &lt;entryPoint&gt;["java", "-jar", "/$&#123;project.build.finalName&#125;.jar"]&lt;/entryPoint&gt; &lt;!--&lt;dockerDirectory&gt;$&#123;project.basedir&#125;/src/main/docker&lt;/dockerDirectory&gt;--&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath&gt;/&lt;/targetPath&gt; &lt;directory&gt;$&#123;project.build.directory&#125;&lt;/directory&gt; &lt;include&gt;$&#123;project.build.finalName&#125;.jar&lt;/include&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;dockerHost&gt;http://207.246.117.90:2375&lt;/dockerHost&gt; &lt;dockerCertPath&gt;/Users/senssic/.docker/&lt;/dockerCertPath&gt; &lt;/configuration&gt;&lt;/plugin&gt; 可以看到执行成功 123456789101112131415Step 1/3 : FROM java:8 ---&gt; d23bdf5b1b1bStep 2/3 : ADD /sc-whorl-web-1.0.1-SNAPSHOT.jar // ---&gt; 274070714038Step 3/3 : ENTRYPOINT [&quot;java&quot;, &quot;-jar&quot;, &quot;/sc-whorl-web-1.0.1-SNAPSHOT.jar&quot;] ---&gt; Running in bff8020fa0f3Removing intermediate container bff8020fa0f3 ---&gt; 1f1b1b0ca7a5ProgressMessage&#123;id=null, status=null, stream=null, error=null, progress=null, progressDetail=null&#125;Successfully built 1f1b1b0ca7a5Successfully tagged 127.0.0.1:5000/sc-whorl/sc-whorl-web:latest[INFO] Built 127.0.0.1:5000/sc-whorl/sc-whorl-web 参考： Docker 远程连接 – dockerd 命令详解]]></content>
      <categories>
        <category>插件</category>
      </categories>
      <tags>
        <tag>maven</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[杂记文档]]></title>
    <url>%2F2018%2F10%2F15%2Fsenssic.github.io%2F201901%2F%E6%9D%82%E8%AE%B0%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[缓存队列相关1.为什么使用mq？mq的优点？解耦,异步,削峰(可以限流发送或接收) 2.mq的缺点有哪些？系统可用性降低(mq挂掉),数据丢失问题,一致性问题,消息顺序问题,消息积压,消息重复问题等需要考虑，导致系统复杂性增加。 3.主流MQ框架的对比 特性 ActiveMQ RabbitMQ RocketMQ Kafka 单机吞吐量 万级，吞吐量比RocketMQ和Kafka要低了一个数量级 万级，吞吐量比RocketMQ和Kafka要低了一个数量级 10万级，RocketMQ也是可以支撑高吞吐的一种MQ 10万级别，这是kafka最大的优点，就是吞吐量高。 一般配合大数据类的系统来进行实时数据计算、日志采集等场景 topic数量对吞吐量的影响 topic可以达到几百，几千个的级别，吞吐量会有较小幅度的下降 这是RocketMQ的一大优势，在同等机器下，可以支撑大量的topic topic从几十个到几百个的时候，吞吐量会大幅度下降 所以在同等机器下，kafka尽量保证topic数量不要过多。如果要支撑大规模topic，需要增加更多的机器资源 时效性 ms级 微秒级，这是rabbitmq的一大特点，延迟是最低的 ms级 延迟在ms级以内 可用性 高，基于主从架构实现高可用性 高，基于主从架构实现高可用性 非常高，分布式架构 非常高，kafka是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 消息可靠性 有较低的概率丢失数据 经过参数优化配置，可以做到0丢失 经过参数优化配置，消息可以做到0丢失 功能支持 MQ领域的功能极其完备 基于erlang开发，所以并发能力很强，性能极其好，延时很低 MQ功能较为完善，还是分布式的，扩展性好 功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用，是事实上的标准 优劣势总结 非常成熟，功能强大，在业内大量的公司以及项目中都有应用 偶尔会有较低概率丢失消息 而且现在社区以及国内应用都越来越少，官方社区现在对ActiveMQ 5.x维护越来越少，几个月才发布一个版本 而且确实主要是基于解耦和异步来用的，较少在大规模吞吐的场景中使用 erlang语言开发，性能极其好，延时很低； 吞吐量到万级，MQ功能比较完备 而且开源提供的管理界面非常棒，用起来很好用 社区相对比较活跃，几乎每个月都发布几个版本分 在国内一些互联网公司近几年用rabbitmq也比较多一些 但是问题也是显而易见的，RabbitMQ确实吞吐量会低一些，这是因为他做的实现机制比较重。 而且erlang开发，国内有几个公司有实力做erlang源码级别的研究和定制？如果说你没这个实力的话，确实偶尔会有一些问题，你很难去看懂源码，你公司对这个东西的掌控很弱，基本职能依赖于开源社区的快速维护和修复bug。 而且rabbitmq集群动态扩展会很麻烦，不过这个我觉得还好。其实主要是erlang语言本身带来的问题。很难读源码，很难定制和掌控。 接口简单易用，而且毕竟在阿里大规模应用过，有阿里品牌保障 日处理消息上百亿之多，可以做到大规模吞吐，性能也非常好，分布式扩展也很方便，社区维护还可以，可靠性和可用性都是ok的，还可以支撑大规模的topic数量，支持复杂MQ业务场景 而且一个很大的优势在于，阿里出品都是java系的，我们可以自己阅读源码，定制自己公司的MQ，可以掌控 社区活跃度相对较为一般，不过也还可以，文档相对来说简单一些，然后接口这块不是按照标准JMS规范走的有些系统要迁移需要修改大量代码 还有就是阿里出台的技术，你得做好这个技术万一被抛弃，社区黄掉的风险，那如果你们公司有技术实力我觉得用RocketMQ挺好的 kafka的特点其实很明显，就是仅仅提供较少的核心功能，但是提供超高的吞吐量，ms级的延迟，极高的可用性以及可靠性，而且分布式可以任意扩展 同时kafka最好是支撑较少的topic数量即可，保证其超高吞吐量 而且kafka唯一的一点劣势是有可能消息重复消费，那么对数据准确性会造成极其轻微的影响，在大数据领域中以及日志采集中，这点轻微影响可以忽略 这个特性天然适合大数据实时计算以及日志收集 不过现在确实越来越多的公司，会去用RocketMQ，确实很不错，但是我提醒一下自己想好社区万一突然黄掉的风险，对自己公司技术实力有绝对自信的，我推荐用RocketMQ，否则回去老老实实用RabbitMQ吧，人是活跃开源社区，绝对不会黄 所以中小型公司，技术实力较为一般，技术挑战不是特别高，用RabbitMQ是不错的选择；大型公司，基础架构研发实力较强，用RocketMQ是很好的选择 如果是大数据领域的实时计算、日志采集等场景，用Kafka是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范 4.mq的高可用模式 RabbitMQ的高可用性 rabbitmq有三种模式：单机模式，普通集群模式，镜像集群模式 单机模式 一般就是你本地启动了玩玩儿的，没人生产用单机模式 普通集群模式 在多台机器上启动多个rabbitmq实例，每个机器启动一个。但是你创建的queue，只会放在一个rabbtimq实例上，但是每个实例都同步queue的元数据。消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从queue所在实例上拉取数据过来。 这种方式非真正的集群,没有高可用,实例节点挂掉mq就会不可用,只是提高了连接的吞吐量,而且由于数据位于不同的实例上,当访问不在连接的实例上会有很多这样的mq内部通讯。 镜像集群模式 真正的rabbitmq的高可用模式，跟普通集群模式不一样的是，创建的queue，无论元数据还是queue里的消息都会存在于多个实例上，每次写消息到queue的时候，都会自动把消息到多个实例的queue里进行消息同步。 坏处在于，第一，性能开销也大，消息同步所有机器，导致网络带宽压力和消耗很重！第二，就没有扩展性可言了，如果某个queue负载很重，加机器，新增的机器也包含了这个queue的所有数据，并没有办法线性扩展的queue kafka的高可用性 kafka一个最基本的架构认识：多个broker组成，每个broker是一个节点；创建一个topic，这个topic可以划分为多个partition，每个partition可以存在于不同的broker上，每个partition就放一部分数据。 这是天然的分布式消息队列，就是说一个topic的数据，是分散放在多个机器上的，每个机器就放一部分数据。 实际上rabbitmq之类的，并不是分布式消息队列，他就是传统的消息队列，只不过提供了一些集群、HA的机制，因为无论怎么玩，rabbitmq一个queue的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个queue的完整数据。 kafka 0.8以前，是没有HA机制的，就是任何一个broker宕机了，那个broker上的partition就废了，没法写也没法读，没有什么高可用性可言。 kafka 0.8以后，提供了HA机制，就是replica副本机制。每个partition的数据都会同步到其他机器上，形成自己的多个replica副本。然后所有replica会选举一个leader出来，那么生产和消费都跟这个leader打交道，然后其他replica就是follower。写的时候，leader会负责把数据同步到所有follower上去，读的时候就直接读leader上数据即可。只能读写leader？很简单，要是你可以随意读写每个follower，那么就要care数据一致性的问题，系统复杂度太高，很容易出问题。kafka会均匀的将一个partition的所有replica分布在不同的机器上，这样才可以提高容错性。如果某个broker宕机了，没事儿，那个broker上面的partition在其他机器上都有副本的，如果这上面有某个partition的leader，那么此时会重新选举一个新的leader出来，大家继续读写那个新的leader即可。这就有所谓的高可用性了。 写数据的时候，生产者就写leader，然后leader将数据落地写本地磁盘，接着其他follower自己主动从leader来pull数据。一旦所有follower同步好数据了，就会发送ack给leader，leader收到所有follower的ack之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为） 消费的时候，只会从leader去读，但是只有一个消息已经被所有follower都同步成功返回ack的时候，这个消息才会被消费者读到。 5.消息重复的处理​ 一般mq是不保证发送消息的重复,有极低的概率可能会消息重复.需要靠业务自己保证幂性的,一般使用数据库,redis等来判断幂等。 6.消息丢失情况分析 rabbitmq 生产者弄丢数据 因为网络或其他通讯原因,数据半路可能丢失,一般通过 开启事务（channel.txSelect），然后发送消息，如果消息没有成功被rabbitmq接收到，那么生产者会收到异常报错，此时就可以回滚事务（channel.txRollback），然后重试发送消息；如果收到了消息，那么可以提交事务（channel.txCommit）。但是问题是，rabbitmq事务机制一搞，基本上吞吐量会下来，因为太耗性能。 开启confirm模式，每次写的消息都会分配一个唯一的id，然后如果写入了rabbitmq中，rabbitmq会给你回传一个ack消息，告诉你说这个消息ok了。如果rabbitmq没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。因为确认模式是异步的,所以一般发送端消息丢失都是使用开启confirm模式进行处理避免消息丢失。 rabbitmq弄丢了数据 一般必须开始rabbitmq持久化,这样就算mq挂了,也可以读取之前存储的数据,一般不会丢失,当然也有极其罕见的情况数据还未写入磁盘mq挂了导致的数据丢失,这种概率极低。 设置持久化有两个步骤 第一个是创建queue的时候将其设置为持久化的，这样就可以保证rabbitmq持久化queue的元数据，但是不会持久化queue里的数据； 第二个是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时rabbitmq就会将消息持久化到磁盘上去。必须要同时设置这两个持久化才行，rabbitmq哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。 而且持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者ack了，所以哪怕是在持久化到磁盘之前，rabbitmq挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。 消费端弄丢了数据 一般使用rabbitmq提供的手动ack机制,未被ack的消息,mq会重复进行投递(死信队列). kafka 消费者丢失数据 如果设置为消费者自动提交offset,此时你刚接到消息还未处理,此消息可能就丢失了,一般的做法是关闭自动提交offset，在处理完之后自己手动提交offset，就可以保证数据不会丢。 kafka数据丢失 kafka某个broker宕机，然后重新选举partiton的leader时。此时其他的follower刚好还有些数据没有同步，结果此时leader挂了，然后选举某个follower成leader之后，就少了一些数据。 此时一般是要求起码设置如下4个参数： 给这个topic设置replication.factor参数：这个值必须大于1，要求每个partition必须有至少2个副本 在kafka服务端设置min.insync.replicas参数：这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系，没掉队，这样才能确保leader挂了还有一个follower吧 在producer端设置acks=all：这个是要求每条数据，必须是写入所有replica之后，才能认为是写成功了 在producer端设置retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了 这样配置之后，至少在kafka broker端就可以保证在leader所在broker发生故障，进行leader切换时，数据不会丢失 生产者不会丢数据 如果按照上述的思路设置了ack=all，一定不会丢，你的leader接收到消息，所有的follower都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。 7.保证消息的顺序性​ 场景：比如下单操作，下单成功之后，会发布创建订单和扣减库存消息，但扣减库存消息执行会先于创建订单消息，也就说前者执行成功之后，才能执行后者。 ​ 在 MQ 层面支持消息的顺序处理开销太大，为了极少量的需求，增加整体上的复杂度得不偿失。 所以，还是在应用层面处理比较好，或者业务逻辑进行处理。 应用层解决方式： 1. 消息实体中增加：版本号 &amp; 状态机 &amp; msgid &amp; parent_msgid，通过 parent_msgid 判断消息的顺序（需要全局存储，记录消息的执行状态）。当处理完后更新parent_msgid然后触发mq重试机制,继续其他消费 2. “同步执行”：当一个消息执行完之后，再发布下一个消息。 3.确保只有一个消费者消费,消费者内部使用队列,然后启动多个线程消费队列。 8.处理消息积压​ 由于某些业务场景导致有些队列没有被消费(消费者挂了,或者消费能力弱),一般处理的方式有如下方式. 消费者积极扩容,当发现百万级的消息积压,首先是先把消费者逻辑处理给修正,想办法临时扩容消费者,加大消费者的处理吞吐量 1）先修复consumer的问题，确保其恢复消费速度，然后将现有cnosumer都停掉 2）新建一个topic，partition是原来的10倍，临时建立好原先10倍或者20倍的queue数量 3）然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue 4）接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据 5）这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据 6）等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer机器来消费消息 对于一些消息已被超时丢弃(一般线上不允许设置小时超时),只能通过补录丢失的消息了,在高峰期过后,一点点的将业务数据查询出来,在低谷的时候写个程序模拟生产消息。 这里还是要提醒,要有主动监控消息积压的流程,当发生消息积压的初期就及时处理,如果发现对业务不影响的消息还可以直接删除。 分布式搜索引擎es的基础知识 倒排索引 也常被称为反向索引、置入档案或反向档案，是一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。它是文档检索系统中最常用的数据结构。 ES索引 ES一些概念和数据库进行对比 Relational DB -&gt; Databases -&gt; Tables -&gt; Rows -&gt; Columns Elasticsearch -&gt; Index -&gt; Types -&gt; Documents -&gt; Fields es分布式结构 一个索引可以拆分成多个shard,每个shard存储部分数据。就是说每个shard都有一primary shard，负责写入数据，还有一个或多个replica shard。primary shard写入数据之后,会将数据同步到其他replica shard上去。 es分布式master节点 es集群多个节点,会自动选举一个节点为master节点,主要负责管理工作,维护索引元数据拉,切换primary shard和replica shard身份之类。要是master节点宕机了,会重新选举一个节点为master节点。 es分布式非master master节点会让宕机节点上的primary shard的身份转移到其他一个机器上的replica shard。宕机节点重启之后,master节点会控制将缺失的replica shard分配过去,同步后续修改的数据,让集群恢复正常。 es的工作原理 es写数据过程 1）客户端选择一个node发送请求过去,这个node就被称作coordinating node（协调节点） 2）coordinating node,对document进行路由,将请求转发给对应的node（有primary shard） 3）实际的node上的primary shard处理请求,然后将数据同步到replica node 4）coordinating node,如果发现primary node和所有replica node都处理好之后,就返回响应结果给客户端 es读数据过程 当es写入一个docment时候,会自动给你分配一个全局唯一的doc id,同时es也是根据doc id进行hash路由到对应的primary shard上面去 1）客户端发送请求到任意一个node，成为coordinate node 2）coordinate node对document进行路由，将请求转发到对应的node，此时会使用round-robin随机轮询算法，在primary shard以及其所有replica中随机选择一个，让读请求负载均衡 3）接收请求的node返回document给coordinate node 4）coordinate node返回document给客户端 es搜索数据过程 1）客户端发送请求到一个coordinate node 2）协调节点将搜索请求转发到所有的shard对应的primary shard或replica shard也可以 3）query phase：每个shard将自己的搜索结果（其实就是一些doc id），返回给协调节点，由协调节点进行数据的合并、排序、分页等操作，产出最终结果 4）fetch phase：接着由协调节点，根据doc id去各个节点上拉取实际的document数据，最终返回给客户端 写数据底层原理 1）先写入buffer,在buffer里的时候数据是搜索不到的;同时将数据写入translog日志文件 2）如果buffer快满了,或者到一定时间,就会将buffer数据refresh到一个新的segment file中,但是此时数据不是直接进入segment file的磁盘文件的,而是先进入os cache的,这个过程就是refresh。每隔1秒钟，es将buffer中的数据写入一个新的segment file,每秒钟会产生一个新的磁盘文件,segment file,这个segment file中就存储最近1秒内buffer中写入的数据,但是如果buffer里面此时没有数据,不会执行refresh操作,每秒创建换一个空的segment file,如果buffer里面有数据,默认1秒钟执行一次refresh操作,刷入一个新的segment file中,操作系统里面,磁盘文件其实都有一个东西,叫做os cache,操作系统缓存,就是说数据写入磁盘文件之前,会先进入os cache,先进入操作系统级别的一个内存缓存中去,只要buffer中的数据被refresh操作,刷入os cache中，就代表这个数据就可以被搜索到了,内存 buffer 生成一个新的 segment，刷到文件系统缓存中，Lucene 即可检索这个新 segment,此时segment位于文件内存缓存中,为什么叫es是准实时的？NRT，near real-time,准实时。默认是每隔1秒refresh一次的,所以es是准实时的,因为写入的数据1秒之后才能被看到。可以通过es的restful api或者java api，手动执行一次refresh操作，就是手动将buffer中的数据刷入os cache中，让数据立马就可以被搜索到。只要数据被输入os cache中，buffer就会被清空了，因为不需要保留buffer了，数据在translog里面已经持久化到磁盘去一份了 3）只要数据进入os cache,此时就可以让这个segment file的数据对外提供搜索了 4）重复1~3步骤，新的数据不断进入buffer和translog,不断将buffer数据写入一个又一个新的segment file中去，每次refresh完buffer清空，translog保留。随着这个过程推进，translog会变得越来越大。当translog达到一定长度的时候，就会触发commit操作。buffer中的数据，每隔1秒就被刷到os cache中去，然后这个buffer就被清空了。所以说这个buffer的数据始终是可以保持住不会填满es进程的内存的。每次一条数据写入buffer,同时会写入一条日志到translog日志文件中去,所以这个translog日志文件是不断变大的,当translog日志文件大到一定程度的时候，就会执行commit操作。 5）commit操作发生第一步，就是将buffer中现有数据refresh到os cache中去，清空buffer 6）将一个commit point写入磁盘文件，里面标识着这个commit point对应的所有os cache内存segment file 7）强行将os cache中目前所有的数据都fsync到磁盘文件中去,translog日志文件的作用是什么？就是在你执行commit操作之前，数据要么是停留在buffer中，要么是停留在os cache中，无论是buffer还是os cache都是内存，一旦这台机器死了，内存中的数据就全丢了。所以需要将数据对应的操作写入一个专门的日志文件，translog日志文件中，一旦此时机器宕机，再次重启的时候，es会自动读取translog日志文件中的数据，恢复到内存buffer和os cache中去。 commit操作： 1、写commit point； 2、将os cache数据fsync强刷到磁盘上去； 3、清空translog日志文件 8）将现有的translog清空，然后再次重启启用一个translog，此时commit操作完成。默认每隔30分钟会自动执行一次commit，但是如果translog过大，也会触发commit。整个commit的过程，叫做flush操作。我们可以手动执行flush操作，就是将所有os cache数据刷到磁盘文件中去。不叫做commit操作，flush操作。es中的flush操作，就对应着commit的全过程。我们也可以通过es api，手动执行flush操作，手动将os cache中的数据fsync强刷到磁盘上去，记录一个commit point，清空translog日志文件。 9）translog其实也是先写入os cache的，默认每隔5秒刷一次到磁盘中去，所以默认情况下，可能有5秒的数据会仅仅停留在buffer或者translog文件的os cache中，如果此时机器挂了，会丢失5秒钟的数据。但是这样性能比较好，最多丢5秒的数据。也可以将translog设置成每次写操作必须是直接fsync到磁盘，但是性能会差很多。其实es第一是准实时的，数据写入1秒后可以搜索到；可能会丢失数据的，你的数据有5秒的数据，停留在buffer、translog os cache、segment file os cache中，有5秒的数据不在磁盘上，此时如果宕机，会导致5秒的数据丢失。如果你希望一定不能丢失数据的话，你可以设置个参数每次写入一条数据，都是写入buffer，同时写入磁盘上的translog，但是这会导致写性能、写入吞吐量会下降一个数量级。 Elasticsearch 2.0 新加入的特性。为了保证不丢数据，每次 index、bulk、delete、update 完成的时候，一定触发刷新 translog 到磁盘上，才给请求返回 200 OK。这个改变在提高数据安全性的同时当然也降低了一点性能。 10）如果是删除操作，commit的时候会生成一个.del文件，里面将某个doc标识为deleted状态，那么搜索的时候根据.del文件就知道这个doc被删除了 11）如果是更新操作，就是将原来的doc标识为deleted状态，然后新写入一条数据 12）buffer每次refresh一次，就会产生一个segment file，所以默认情况下是1秒钟一个segment file，segment file会越来越多，此时会定期执行merge 13）每次merge的时候，会将多个segment file合并成一个，同时这里会将标识为deleted的doc给物理删除掉，然后将新的segment file写入磁盘，这里会写一个commit point，标识所有新的segment file，然后打开segment file供搜索使用，同时删除旧的segment file。 es里的写流程，有4个底层的核心概念，refresh、flush、translog、merge,当segment file多到一定程度的时候，es就会自动触发merge操作，将多个segment file给merge成一个segment file。 es搜索的性能优化(几十亿)es搜索优化不是银弹,关键的底层性能影响就是内存的es缓存(filesystem cache) 增加filesystem cache的值设置足够大,确保es机器内存足够大,如果es未命中filesystem cache数据,会到磁盘中读取十分影响读取的性能。(filesystem cache尽量足够大) 尽量少的字段存放到es这样filesystem cache能更大存放es数据,真正大的数据存放到外部mysql或hbase中通过es中的关键字段到外置存储中查询。(filesystem cache尽量保留关键) 数据预热,如果实在是有数据被存放在了磁盘中,对于经常访问的数据,可以定时查询一下,保证filesystem cache中的都基本是热数据,提升体验。(filesystem cach尽量多存放热数据) 冷热分离,将热数据和冷数据尽量水平拆分,这样可以保证尽可能多的热数据位于filesystem cache中。(filesystem cach尽量多存放热数据) 优化document模型设计,对于原始数据有关联的结果,尽量在写入的时候就将结果写入,尽量避免使用复杂关联的查询。复杂的计算尽量在程序中做。(es尽量少的计算合并读取) 分页的优化,es的分页,分页深度越大越慢,因为是分布式存储数据,分页深度大的情况下,协调节点依然会将pagesize*pageindex的量的数据查询出来然后做合并排序等操作,再取出分页的数据。 对于不需要跳转,只需要一页一页下翻的分页,可以使用scroll api,其原理是使用了es数据快照,将查询出来的数据进行快照,然后通过游标一页一页的展示,缺点是无法指定页数以及页跳转。 分布式缓存为什么用缓存缓存缺点 一般用缓存是为了高并发或高性能 缓存的缺点 缓存击穿 缓存雪崩 缓存与数据库双写不一致 缓存并发竞争 redis缓存相关知识redis和memcache主要区别 redis支持丰富的数据类型,memcache只支持简单的key-value存储模式 redis是单线程对于小数据有很高的效率,memcache是多线程对于大数据存储可能效率高些 redis支持原生的集群高可用,而memcache没有高可用可能需要依赖客户端的分片写入 redis线程模型Redis 基于 Reactor 模式开发了自己的网络事件处理器[文件事件处理器(file event handler)] 文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字, 并根据套接字目前执行的任务来为套接字关联不同的事件处理器。当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时， 与操作相对应的文件事件就会产生, 这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。虽然文件事件处理器以单线程方式运行, 但通过使用 I/O 多路复用程序来监听多个套接字,文件事件处理器既实现了高性能的网络通信模型，,又可以很好地与 redis 服务器中其他同样以单线程方式运行的模块进行对接,保持了 Redis 内部单线程设计的简单性。 Redis 线程模型 redis单线程模型 BIO,NIO,AIO redis单线程模型高性能原因 纯内存操作 单线程避免多线程的上下文切换消耗 多路IO非阻塞模型,不同环境使用实现不一样(Solaries 10,linux epoll,mac os kqueue,select等) redis数据类型以及使用场景 string hash list set sorted set HyperLogLog-基数统计,有偏差 redis的过期策略和淘汰机制 过期策略,定期删除+惰性删除 redis检查过期key是通过定期随机检查[100ms,随机是因为如果是量很大的话100ms检测一遍会很消耗CPU所以使用随机定量key进行检测]和惰性检测[当再次访问key时判断是否过期] 淘汰机制,当reids内存存放的key很多很大的时候,会触发redis删除一些key[内存淘汰] 1）noeviction：当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用 2）allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的） 3）allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的key给干掉啊 4）volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key（这个一般不太合适） 5）volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key 6）volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除 ​ redis高并发和高可用[现在可以直接使用redis集群进行读写的水平扩展]redis单机一般可支持5w~10w的QPS,再高的话就会有单机瓶颈,一般可以使用redis读写分离来水平扩展redis的读性能,master负责写入和同步多个slave数据,多个slave负责读取,这样的主从架构可以随时水平扩展进而可以支持高于10w的QPS。如果采用了主从架构必须开启master node的持久化, redis读写分离架构中的master和slave数据复制[现在一般不用这种架构而是使用redis集群架构]1、复制的完整流程 （1）slave node启动，仅仅保存master node的信息，包括master node的host和ip，但是复制流程没开始 master host和ip是从哪儿来的，redis.conf里面的slaveof配置的 （2）slave node内部有个定时任务，每秒检查是否有新的master node要连接和复制，如果发现，就跟master node建立socket网络连接（3）slave node发送ping命令给master node（4）口令认证，如果master设置了requirepass，那么salve node必须发送masterauth的口令过去进行认证（5）master node第一次执行全量复制，将所有数据发给slave node（6）master node后续持续将写命令，异步复制给slave node 2、数据同步相关的核心机制 就是第一次slave连接msater的时候，执行的全量复制，那个过程里面一些细节的机制 （1）master和slave都会维护一个offset master会在自身不断累加offset，slave也会在自身不断累加offsetslave每秒都会上报自己的offset给master，同时master也会保存每个slave的offset,master和slave都要知道各自的数据的offset，才能知道互相之间的数据不一致的情况 （2）backlog master node有一个backlog，默认是1MB大小master node给slave node复制数据时，也会将数据在backlog中同步写一份backlog主要是用来做全量复制中断候的增量复制的 （3）master run id info server，可以看到master run id如果根据host+ip定位master node，是不靠谱的，如果master node重启或者数据出现了变化，那么slave node应该根据不同的run id区分，run id不同就做全量复制如果需要不更改run id重启redis，可以使用redis-cli debug reload命令 （4）psync 从节点使用psync从master node进行复制，psync runid offsetmaster node会根据自身的情况返回响应信息，可能是FULLRESYNC runid offset触发全量复制，可能是CONTINUE触发增量复制 3、全量复制 （1）master执行bgsave，在本地生成一份rdb快照文件（2）master node将rdb快照文件发送给salve node，如果rdb复制时间超过60秒（repl-timeout），那么slave node就会认为复制失败，可以适当调节大这个参数（3）对于千兆网卡的机器，一般每秒传输100MB，6G文件，很可能超过60s（4）master node在生成rdb时，会将所有新的写命令缓存在内存中，在salve node保存了rdb之后，再将新的写命令复制给salve node（5）client-output-buffer-limit slave 256MB 64MB 60，如果在复制期间，内存缓冲区持续消耗超过64MB，或者一次性超过256MB，那么停止复制，复制失败（6）slave node接收到rdb之后，清空自己的旧数据，然后重新加载rdb到自己的内存中，同时基于旧的数据版本对外提供服务（7）如果slave node开启了AOF，那么会立即执行BGREWRITEAOF，重写AOF rdb生成、rdb通过网络拷贝、slave旧数据的清理、slave aof rewrite，很耗费时间 如果复制的数据量在4G~6G之间，那么很可能全量复制时间消耗到1分半到2分钟 4、增量复制 （1）如果全量复制过程中，master-slave网络连接断掉，那么salve重新连接master时，会触发增量复制（2）master直接从自己的backlog中获取部分丢失的数据，发送给slave node，默认backlog就是1MB（3）msater就是根据slave发送的psync中的offset来从backlog中获取数据的 5、heartbeat 主从节点互相都会发送heartbeat信息 master默认每隔10秒发送一次heartbeat，salve node每隔1秒发送一个heartbeat 6、异步复制 master每次接收到写命令之后，现在内部写入数据，然后异步发送给slave node redis高可用架构1、哨兵sentinal 哨兵是redis集群架构中非常重要的一个组件，主要功能如下 （1）集群监控，负责监控redis master和slave进程是否正常工作（2）消息通知，如果某个redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员（3）故障转移，如果master node挂掉了，会自动转移到slave node上（4）配置中心，如果故障转移发生了，通知client客户端新的master地址 哨兵本身也是分布式的，作为一个哨兵集群去运行，互相协同工作 （1）故障转移时，判断一个master node是宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题（2）即使部分哨兵节点挂掉了，哨兵集群还是能正常工作的，因为如果一个作为高可用机制重要组成部分的故障转移系统本身是单点的,本身就不能高可用 （3）哨兵至少需要三个才能故障转移,因为如果只有两个哨兵其中一个挂掉后不满足2的majority=2,不会允许执行故障转移。 4、经典的3节点哨兵集群 Master,Sentinal1 Slave1,Sentinal2 Slave2,Sentinal3 Configuration: quorum = 2 如果M1所在机器宕机了，那么三个哨兵还剩下2个，S2和S3可以一致认为master宕机，然后选举出一个来执行故障转移同时3个哨兵的majority是2，所以还剩下的2个哨兵运行着，就可以允许执行故障转移。 redis持久化方式[AOF,RDB]以及优缺点1、RDB和AOF两种持久化机制的介绍 RDB持久化机制，对redis中的数据执行周期性的持久化 AOF机制对每条写入命令作为日志，以append-only的模式写入一个日志文件中，在redis重启的时候，可以通过回放AOF日志中的写入指令来重新构建整个数据集 通过RDB或AOF，都可以将redis内存中的数据给持久化到磁盘上面来,如果同时使用RDB和AOF两种持久化机制，那么在redis重启的时候，会使用AOF来重新构建数据，因为AOF中的数据更加完整 2、RDB持久化机制的优点 （1）RDB会生成多个数据文件，每个数据文件都代表了某一个时刻中redis的数据，这种多个数据文件的方式，非常适合做冷备，以预定好的备份策略来定期备份redis中的数据 （2）RDB对redis对外提供的读写服务，影响非常小，可以让redis保持高性能，因为redis主进程只需要fork一个子进程，让子进程执行磁盘IO操作来进行RDB持久化即可 （3）相对于AOF持久化机制来说，直接基于RDB数据文件来重启和恢复redis进程，更加快速 3、RDB持久化机制的缺点 （1）如果想要在redis故障时，尽可能少的丢失数据，那么RDB没有AOF好。一般来说，RDB数据快照文件，都是每隔5分钟，或者更长时间生成一次，这个时候就得接受一旦redis进程宕机，那么会丢失最近5分钟的数据 （2）RDB每次在fork子进程来执行RDB快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒 4、AOF持久化机制的优点 （1）AOF可以更好的保护数据不丢失，一般AOF会每隔1秒，通过一个后台线程执行一次fsync操作，最多丢失1秒钟的数据 （2）AOF日志文件以append-only模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复 （3）AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在rewrite log的时候，会对其中的指导进行压缩，创建出一份需要恢复数据的最小日志出来。再创建新日志文件的时候，老的日志文件还是照常写入。当新的merge后的日志文件ready的时候，再交换新老日志文件即可。 （4）AOF日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall命令给删了，然后再将该AOF文件放回去，就可以通过恢复机制，自动恢复所有数据 5、AOF持久化机制的缺点 （1）对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大 （2）AOF开启后，支持的写QPS会比RDB支持的写QPS低，因为AOF一般会配置成每秒fsync一次日志文件，当然，每秒一次fsync，性能也还是很高的 （3）以前AOF发生过bug，就是通过AOF记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似AOF这种较为复杂的基于命令日志/merge/回放的方式，比基于RDB每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有bug。不过AOF就是为了避免rewrite过程导致的bug，因此每次rewrite并不是基于旧的指令日志进行merge的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。 6、RDB和AOF到底该如何选择 （1）不要仅仅使用RDB，因为那样会导致你丢失很多数据 （2）也不要仅仅使用AOF，因为那样有两个问题，第一，你通过AOF做冷备，没有RDB做冷备，来的恢复速度更快; 第二，RDB每次简单粗暴生成数据快照，更加健壮，可以避免AOF这种复杂的备份和恢复机制的bug （3）综合使用AOF和RDB两种持久化机制，用AOF来保证数据不丢失，作为数据恢复的第一选择; 用RDB来做不同程度的冷备，在AOF文件都丢失或损坏不可用的时候，还可以使用RDB来进行快速的数据恢复 redis cluster集群(数据会分片到相应的redis master-slave主从架构)如果你的数据量很少，主要是承载高并发高性能的场景，比如你的缓存一般就几个G，单机足够了使用单master进行读写分离就行了replication，一个mater，多个slave，要几个slave跟你的要求的读吞吐量有关系，然后自己搭建一个sentinal集群，去保证redis主从架构的高可用性。 redis cluster，主要是针对海量数据+高并发+高可用的场景，海量数据，如果你的数据量很大，那么建议就用redis cluster。 redis cluster数据分布算法 hash算法 -&gt; 一致性hash算法（memcached） -&gt; redis cluster，hash slot算法 用不同的算法，就决定了在多个master节点的时候，数据如何分布到这些节点上去，解决这个问题 1、redis cluster介绍 redis cluster （1）自动将数据进行分片，每个master上放一部分数据（2）提供内置的高可用支持，部分master不可用时，还是可以继续工作的 在redis cluster架构下，每个redis要放开两个端口号，比如一个是6379，另外一个就是加10000的端口号，比如16379 16379端口号是用来进行节点间通信的，也就是cluster bus的东西，集群总线。cluster bus的通信，用来进行故障检测，配置更新，故障转移授权 cluster bus用了另外一种二进制的协议，主要用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间 2、最老土的hash算法和弊端（大量缓存重建） 3、一致性hash算法（自动缓存迁移）+虚拟节点（自动负载均衡） 4、redis cluster的hash slot算法 redis cluster有固定的16384个hash slot，对每个key计算CRC16值，然后对16384取模，可以获取key对应的hash slot redis cluster中每个master都会持有部分slot，比如有3个master，那么可能每个master持有5000多个hash slot hash slot让node的增加和移除很简单，增加一个master，就将其他master的hash slot移动部分过去，减少一个master，就将它的hash slot移动到其他master上去 移动hash slot的成本是非常低的 客户端的api，可以对指定的数据，让他们走同一个hash slot，通过hash tag来实现 节点间的内部通讯机制 一、节点间的内部通信机制 1、基础通信原理 （1）redis cluster节点间采取gossip协议进行通信 跟集中式不同，不是将集群元数据（节点信息，故障，等等）集中存储在某个节点上，而是互相之间不断通信，保持整个集群所有节点的数据是完整的 维护集群的元数据用得，集中式，一种叫做gossip 集中式(如zookeeper)：好处在于，元数据的更新和读取，时效性非常好，一旦元数据出现了变更，立即就更新到集中式的存储中，其他节点读取的时候立即就可以感知到; 不好在于，所有的元数据的跟新压力全部集中在一个地方，可能会导致元数据的存储有压力 gossip：好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续，打到所有节点上去更新，有一定的延时，降低了压力; 缺点，元数据更新有延时，可能导致集群的一些操作会有一些滞后 我们刚才做reshard，去做另外一个操作，会发现说，configuration error，达成一致 （2）10000端口 每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号+10000，比如7001，那么用于节点间通信的就是17001端口 每隔节点每隔一段时间都会往另外几个节点发送ping消息，同时其他几点接收到ping之后返回pong （3）交换的信息 故障信息，节点的增加和移除，hash slot信息，等等 2、gossip协议 gossip协议包含多种消息，包括ping，pong，meet，fail，等等 meet: 某个节点发送meet给新加入的节点，让新节点加入集群中，然后新节点就会开始与其他节点进行通信 redis-trib.rb add-node 其实内部就是发送了一个gossip meet消息，给新加入的节点，通知那个节点去加入我们的集群 ping: 每个节点都会频繁给其他节点发送ping，其中包含自己的状态还有自己维护的集群元数据，互相通过ping交换元数据 每个节点每秒都会频繁发送ping给其他的集群，ping，频繁的互相之间交换数据，互相进行元数据的更新 pong: 返回ping和meet，包含自己的状态和其他信息，也可以用于信息广播和更新 fail: 某个节点判断另一个节点fail之后，就发送fail给其他节点，通知其他节点，指定的节点宕机了 3、ping消息深入 ping很频繁，而且要携带一些元数据，所以可能会加重网络负担 每个节点每秒会执行10次ping，每次会选择5个最久没有通信的其他节点 当然如果发现某个节点通信延时达到了cluster_node_timeout / 2，那么立即发送ping，避免数据交换延时过长，落后的时间太长了 比如说，两个节点之间都10分钟没有交换数据了，那么整个集群处于严重的元数据不一致的情况，就会有问题 所以cluster_node_timeout可以调节，如果调节比较大，那么会降低发送的频率 每次ping，一个是带上自己节点的信息，还有就是带上1/10其他节点的信息，发送出去，进行数据交换 至少包含3个其他节点的信息，最多包含总节点-2个其他节点的信息 二、面向集群的jedis内部实现原理 开发，jedis，redis的java client客户端，redis cluster，jedis cluster api jedis cluster api与redis cluster集群交互的一些基本原理 1、基于重定向的客户端 redis-cli -c，自动重定向 （1）请求重定向 客户端可能会挑选任意一个redis实例去发送命令，每个redis实例接收到命令，都会计算key对应的hash slot 如果在本地就在本地处理，否则返回moved给客户端，让客户端进行重定向 cluster keyslot mykey，可以查看一个key对应的hash slot是什么 用redis-cli的时候，可以加入-c参数，支持自动的请求重定向，redis-cli接收到moved之后，会自动重定向到对应的节点执行命令 （2）计算hash slot 计算hash slot的算法，就是根据key计算CRC16值，然后对16384取模，拿到对应的hash slot 用hash tag可以手动指定key对应的slot，同一个hash tag下的key，都会在一个hash slot中，比如set mykey1:{100}和set mykey2:{100} （3）hash slot查找 节点间通过gossip协议进行数据交换，就知道每个hash slot在哪个节点上 2、smart jedis （1）什么是smart jedis 基于重定向的客户端，很消耗网络IO，因为大部分情况下，可能都会出现一次请求重定向，才能找到正确的节点 所以大部分的客户端，比如java redis客户端，就是jedis，都是smart的 本地维护一份hashslot -&gt; node的映射表，缓存，大部分情况下，直接走本地缓存就可以找到hashslot -&gt; node，不需要通过节点进行moved重定向 （2）JedisCluster的工作原理 在JedisCluster初始化的时候，就会随机选择一个node，初始化hashslot -&gt; node映射表，同时为每个节点创建一个JedisPool连接池 每次基于JedisCluster执行操作，首先JedisCluster都会在本地计算key的hashslot，然后在本地映射表找到对应的节点 如果那个node正好还是持有那个hashslot，那么就ok; 如果说进行了reshard这样的操作，可能hashslot已经不在那个node上了，就会返回moved 如果JedisCluter API发现对应的节点返回moved，那么利用该节点的元数据，更新本地的hashslot -&gt; node映射表缓存 重复上面几个步骤，直到找到对应的节点，如果重试超过5次，那么就报错，JedisClusterMaxRedirectionException jedis老版本，可能会出现在集群某个节点故障还没完成自动切换恢复时，频繁更新hash slot，频繁ping节点检查活跃，导致大量网络IO开销 jedis最新版本，对于这些过度的hash slot更新和ping，都进行了优化，避免了类似问题 （3）hashslot迁移和ask重定向 如果hash slot正在迁移，那么会返回ask重定向给jedis jedis接收到ask重定向之后，会重新定位到目标节点去执行，但是因为ask发生在hash slot迁移过程中，所以JedisCluster API收到ask是不会更新hashslot本地缓存 已经可以确定说，hashslot已经迁移完了，moved是会更新本地hashslot-&gt;node映射表缓存的 三、高可用性与主备切换原理 redis cluster的高可用的原理，几乎跟哨兵是类似的 1、判断节点宕机 如果一个节点认为另外一个节点宕机，那么就是pfail，主观宕机 如果多个节点都认为另外一个节点宕机了，那么就是fail，客观宕机，跟哨兵的原理几乎一样，sdown，odown 在cluster-node-timeout内，某个节点一直没有返回pong，那么就被认为pfail 如果一个节点认为某个节点pfail了，那么会在gossip ping消息中，ping给其他节点，如果超过半数的节点都认为pfail了，那么就会变成fail 2、从节点过滤 对宕机的master node，从其所有的slave node中，选择一个切换成master node 检查每个slave node与master node断开连接的时间，如果超过了cluster-node-timeout * cluster-slave-validity-factor，那么就没有资格切换成master 这个也是跟哨兵是一样的，从节点超时过滤的步骤 3、从节点选举 哨兵：对所有从节点进行排序，slave priority，offset，run id 每个从节点，都根据自己对master复制数据的offset，来设置一个选举时间，offset越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举 所有的master node开始slave选举投票，给要进行选举的slave进行投票，如果大部分master node（N/2 + 1）都投票给了某个从节点，那么选举通过，那个从节点可以切换成master 从节点执行主备切换，从节点切换为主节点 4、与哨兵比较 整个流程跟哨兵相比，非常类似，所以说，redis cluster功能强大，直接集成了replication和sentinal的功能 没有办法去给大家深入讲解redis底层的设计的细节，核心原理和设计的细节，那个除非单独开一门课，redis底层原理深度剖析，redis源码 对于咱们这个架构课来说，主要关注的是架构，不是底层的细节，对于架构来说，核心的原理的基本思路，是要梳理清晰的 缓存穿透和缓存雪崩 缓存雪崩 缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。 事前：redis高可用，主从+哨兵，redis cluster，避免全盘崩溃 事中：本地ehcache缓存 + hystrix限流&amp;降级，避免MySQL被打死 事后：redis持久化，快速恢复缓存数据 缓存穿透 缓存穿透是指查询一个一定不存在的数据,由于缓存一般是命中后才写入缓存,如果有大量这样的查询请求(黑客攻击,恶意请求),会全部打到DB上,导致DB宕机 解决方式: ​ 1,使用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉 ​ 2,如果查询未命中将未命中的key仍然写入缓存,value为UNKONW等,过期时间为5到10分钟来冲抵短时恶意攻击 缓存击穿 对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。 1.使用互斥锁(mutex key),推荐使用 ​ 就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。 2.热点key设置不过期,或者使用快过期时预热key 3.采用netflix的hystrix,抵挡冲击 缓存数据库双写不一致 先更新数据库,再更新缓存 这种操作太费时费力一般不使用 先更新数据库，再删除缓存这种策略比较多平台使用，如：Facebook。但是这种策略也存在一些问题，如：一、脏数据造成脏数据的原因主要由并发引起，如： 用户A请求数据A 数据A缓存失效 用户A从数据库中得到旧数据数据A 用户B更新了数据A（新数据） 用户B删除了缓存 用户A将查到旧数据写入了缓存 此时就产生了脏数据，虽然这种概率非常小，但对于更新不频繁的网站来说，此时的脏数据就是个很严重的错误。 二、缓存删除失败 用户A更新了数据A 用户A删除数据A的缓存失败 用户B读到数据A缓存的旧数据 此时就产生了数据不一致的问题。 解决方案 置缓存的有效时间（最简单的方案）优点:易操作 缺点:会存在短时间内的旧数据,如果数据量太多，缓存有效时间短，容易发生一段时间内缓存大量失效，此时的数据库压力突然剧增，引发缓存雪崩现象（缓存有效时间为随机值减少发生缓存雪崩的可能性） 消息队列（比较复杂，需要引入消息队列系统） 步骤： 更新数据库； 删除缓存失败； 将需要删除的Key发送到消息队列； 隔断时间从消息队列中拉取要删除的key； 继续删除，直至成功为止。 优点：不会引发缓存雪崩,只删除需要删除的缓存 缺点：引入了消息系统（增加了系统的复杂性） 先删除缓存，推荐使用，但是也会出现脏数据的问题： 用户A删除缓存失败 用户A成功更新了数据 或者 用户A删除了缓存； 用户B读取缓存，缓存不存在； 用户B从数据库拿到旧数据； 用户B更新了缓存； 用户A更新了数据。 以上两种情况都能造成脏数据的产生。 解决方式同上 redis并发竞争问题一般使用分布式锁(zookeeper)保证统一时间只有一个实例获取到锁 使用版本控制和锁重试机制来处理并发的竞争顺序 分布式系统​ 分布式系统一般使用RPC框架相互调用,RPC一般提供了负载,超时重试,自动感知上下线.等如果不使用RPC框架就需要自己处理这些复杂的问题。 dubbo工作原理注册中心挂了可以继续通讯么1.dubbo工作原理 第一层：service层，接口层，给服务提供者和消费者来实现的 第二层：config层，配置层，主要是对dubbo进行各种配置的 第三层：proxy层，服务代理层，透明生成客户端的stub和服务单的skeleton 第四层：registry层，服务注册层，负责服务的注册与发现 第五层：cluster层，集群层，封装多个服务提供者的路由以及负载均衡，将多个实例组合成一个服务 第六层：monitor层，监控层，对rpc接口的调用次数和调用时间进行监控 第七层：protocol层，远程调用层，封装rpc调用 第八层：exchange层，信息交换层，封装请求响应模式，同步转异步 第九层：transport层，网络传输层，抽象mina和netty为统一接口 第十层：serialize层，数据序列化层 工作流程： 1）第一步，provider向注册中心去注册 2）第二步，consumer从注册中心订阅服务，注册中心会通知consumer注册好的服务 3）第三步，consumer调用provider 4）第四步，consumer和provider都异步的通知监控中心 2.注册中心挂了可以继续通信吗？ ​ 可以,因为刚开始初始化的时候,消费者会将提供者的地址等信息拉取到本地缓存,所以注册中心挂了可以继续通信,但是因为信息是旧的如果服务方挂了无法感知。 dubbo的通讯协议以及序列化协议1、dubbo协议 Dubbo缺省协议采用单一长连接和NIO异步通讯，适合于小数据量大并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况。 12345678缺省协议，使用基于mina1.1.7+hessian3.2.1的tbremoting交互。连接个数：单连接连接方式：长连接传输协议：TCP传输方式：NIO异步传输序列化：Hessian二进制序列化适用范围：传入传出参数数据包较小（建议小于100K），消费者比提供者个数多，单一消费者无法压满提供者，尽量不要用dubbo协议传输大文件或超大字符串。适用场景：常规远程服务方法调用 123456789101112131415161718192021为什么要消费者比提供者个数多：因dubbo协议采用单一长连接，假设网络为千兆网卡(1024Mbit=128MByte)，根据测试经验数据每条连接最多只能压满7MByte(不同的环境可能不一样，供参考)，理论上1个服务提供者需要20个服务消费者才能压满网卡。为什么不能传大包：因dubbo协议采用单一长连接，如果每次请求的数据包大小为500KByte，假设网络为千兆网卡(1024Mbit=128MByte)，每条连接最大7MByte(不同的环境可能不一样，供参考)，单个服务提供者的TPS(每秒处理事务数)最大为：128MByte / 500KByte = 262。单个消费者调用单个服务提供者的TPS(每秒处理事务数)最大为：7MByte / 500KByte = 14。如果能接受，可以考虑使用，否则网络将成为瓶颈。为什么采用异步单一长连接：因为服务的现状大都是服务提供者少，通常只有几台机器，而服务的消费者多，可能整个网站都在访问该服务，比如Morgan的提供者只有6台提供者，却有上百台消费者，每天有1.5亿次调用，如果采用常规的hessian服务，服务提供者很容易就被压跨，通过单一连接，保证单一消费者不会压死提供者，长连接，减少连接握手验证等，并使用异步IO，复用线程池，防止C10K问题。 2、RMI RMI协议采用JDK标准的java.rmi.*实现，采用阻塞式短连接和JDK标准序列化方式 12345678Java标准的远程调用协议。连接个数：多连接连接方式：短连接传输协议：TCP传输方式：同步传输序列化：Java标准二进制序列化适用范围：传入传出参数数据包大小混合，消费者与提供者个数差不多，可传文件。适用场景：常规远程服务方法调用，与原生RMI服务互操作 3、hessian Hessian协议用于集成Hessian的服务，Hessian底层采用Http通讯，采用Servlet暴露服务，Dubbo缺省内嵌Jetty作为服务器实现 123456789基于Hessian的远程调用协议。连接个数：多连接连接方式：短连接传输协议：HTTP传输方式：同步传输序列化：Hessian二进制序列化适用范围：传入传出参数数据包较大，提供者比消费者个数多，提供者压力较大，可传文件。适用场景：页面传输，文件传输，或与原生hessian服务互操作 4、http 采用Spring的HttpInvoker实现 123456789基于http表单的远程调用协议。连接个数：多连接连接方式：短连接传输协议：HTTP传输方式：同步传输序列化：表单序列化（JSON）适用范围：传入传出参数数据包大小混合，提供者比消费者个数多，可用浏览器查看，可用表单或URL传入参数，暂不支持传文件。适用场景：需同时给应用程序和浏览器JS使用的服务。 5、webservice 基于CXF的frontend-simple和transports-http实现 1234567基于WebService的远程调用协议。连接个数：多连接连接方式：短连接传输协议：HTTP传输方式：同步传输序列化：SOAP文本序列化适用场景：系统集成，跨语言调用。 6、thrif Thrift是Facebook捐给Apache的一个RPC框架，当前 dubbo 支持的 thrift 协议是对 thrift 原生协议的扩展，在原生协议的基础上添加了一些额外的头信息，比如service name，magic number等。 dubbo负载均衡Random LoadBalance 随机，按权重设置随机概率。 在一个截面上碰撞的概率高，但调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。 RoundRobin LoadBalance 轮询，按公约后的权重设置轮询比率。 存在慢的提供者累积请求的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。 LeastActive LoadBalance 最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。 使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。 ConsistentHash LoadBalance 一致性 Hash，相同参数的请求总是发到同一提供者。 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。 分布式幂等1.数据库乐观锁 2.分布式锁(redis,zookeeper) 3.token机制，防止页面重复提交 http://825635381.iteye.com/blog/2276077 分布式请求顺序性一般不建议保证分布式的顺序性,因为复杂度太高,如果实在是需要可以使用维护内存队列。 zookeeper的使用场景1、负载均衡 在分布式系统中，负载均衡是一种普遍的技术。ZooKeeper作为一个集群，负责数据的存储以及一系列分布式协调。所有的请求，会通过ZooKeeper通过一些调度策略去协调调度哪一台服务器。 2、分布式协调/通知 分布式协调/通知服务是分布式系统中将不同的分布式组件结合起来。通常需要一个协调者来控制整个系统的运行流程，这个协调者便于将分布式协调的职责从应用中分离出来，从而可以大大减少系统之间的耦合性，而且能够显著提高系统的可扩展性。 ZooKeeper中特有的Watcher注册与异步通知机制，能够很好地实现分布式环境下不同机器，甚至是不同系统之间的协调与通知，从而实现对数据变更的实时处理。基于ZooKeeper实现分布式协调与通知功能，通常的作坊式不同的客户端对ZooKeeper上同一个数据节点进行Watcher注册，监听数据节点的变化，如果数据节点发生变化，那么所有订阅的客户端都能够接受到相应的Watcher通知，并作出相应的处理。 3、集群管理 集群管理包括集群监控和集群控制。前者侧重对集群运行状态的收集，后者则是对集群进行操作与控制。在传统的基于Agent的分布式管理体系中，都是通过在集群中每台机器上部署一个Agent，由这个Agent负责主动向指定的一个监控中心系统汇报自己所在机器的状态。在集群规模适中的场景下，这确实是一种在生产实践中广泛使用的解决方案，但一旦系统的业务场景增多，这种方案就不好了。大规模升级困难，统一的Agent无法满足多样的需求等问题。 4、分布式锁 分布式锁是控制分布式系统之间同步访问共享资源的一种方式。如果不同的系统或是同一个系统的不同主机之间共享一个或一组资源，那么访问这些资源的时候，往往需要通过一些互斥手段来防止彼此之间的干扰，以保证一致性，在这种情况下，需要使用分布式锁。 分布式锁1.基于redis 2.基于zookeeper(推荐) 分布式session的处理 tomcat+redis Tomcat RedisSessionManager的东西，让所有我们部署的tomcat都将session数据存储到redis即可。 在tomcat的配置文件中，配置一下 12345678910111213141516171819202122&lt;Valve className="com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve" /&gt; &lt;Manager className="com.orangefunction.tomcat.redissessions.RedisSessionManager" host="&#123;redis.host&#125;" port="&#123;redis.port&#125;" database="&#123;redis.dbnum&#125;" maxInactiveInterval="60"/&gt;-- 哨兵模式&lt;Valve className="com.orangefunction.tomcat.redissessions.RedisSessionHandlerValve" /&gt;&lt;Manager className="com.orangefunction.tomcat.redissessions.RedisSessionManager" sentinelMaster="mymaster" sentinels="&lt;sentinel1-ip&gt;:26379,&lt;sentinel2-ip&gt;:26379,&lt;sentinel3-ip&gt;:26379" maxInactiveInterval="60"/&gt; 还可以用上面这种方式基于redis哨兵支持的redis高可用集群来保存session数据 spring session + redis 不仅可以使用redis spring session还可以基于数据库等其他存储 spring session 分布式事务 两阶段提交(效率低下不推荐) TCC(需要自己写大量的回滚逻辑复杂不推荐) 1）Try阶段：对各个服务的资源做检测以及对资源进行锁定或者预留 2）Confirm阶段：各个服务中执行实际的操作 3）Cancel阶段：如果任何一个服务的业务方法执行出错，就需要进行补偿，就是执行已经执行成功的业务逻辑的回滚操作 本地消息表(严重依赖于数据库的消息表,高并发场景无法扩展,比较少用) 1）A系统在自己本地一个事务里操作同时，插入一条数据到消息表 2）A系统将这个消息发送到MQ中去 3）B系统接收到消息之后，在一个事务里，往自己本地消息表里插入一条数据，同时执行其他的业务操作，如果这个消息已经被处理过了，那么此时这个事务会回滚，这样保证不会重复处理消息 4）B系统执行成功之后，就会更新自己本地消息表的状态以及A系统消息表的状态 5）如果B系统处理失败了，那么就不会更新消息表状态，那么此时A系统会定时扫描自己的消息表，如果有没处理的消息，会再次发送到MQ中去，让B再次处理 6）这个方案保证了最终一致性，哪怕B事务失败了，但是A会不断重发消息，直到B那边成功为止 可靠消息最终一致性 基于MQ来实现事务 1）A系统先发送一个prepared消息到mq，如果这个prepared消息发送失败那么就直接取消操作别执行了 2）如果这个消息发送成功过了，那么接着执行本地事务，如果成功就告诉mq发送确认消息，如果失败就告诉mq回滚消息 3）如果发送了确认消息，那么此时B系统会接收到确认消息，然后执行本地的事务 4）mq会自动定时轮询所有prepared消息回调你的接口，询问这个消息是不是本地事务处理失败了，这里你就可以查下数据库看之前本地事务是否执行，如果回滚了，那么这里也回滚吧。这个就是避免可能本地事务执行成功了，别确认消息发送失败了。 5）要是系统B的事务失败了，自动不断重试直到成功，如果实在是不行，要么就是针对重要的资金类业务进行回滚，比如B系统本地回滚后，想办法通知系统A也回滚；或者是发送报警由人工来手工回滚和补偿 最大努力通知 1）系统A本地事务执行完之后，发送个消息到MQ 2）有个专门消费MQ的最大努力通知服务，这个服务会消费MQ然后写入数据库中记录下来，或者是放入个内存队列也可以，接着调用系统B的接口 3）要是系统B执行成功就ok了；要是系统B执行失败了，那么最大努力通知服务就定时尝试重新调用系统B，反复N次，最后还是不行就放弃 ​ 别严格的场景，用的是TCC来保证强一致性；然后其他的一些场景基于了MQ或最大通知来实现了分布式事务,一般很少使用事务,一般是快速发现问题修复数据。 分库分表分库分表参考 分库分表中间件 cobar(不推荐) 阿里b2b团队开发和开源的,属于proxy层方案,功能简单且没人维护了 TDDL(不推荐) 淘宝团队开发的,属于client层方案,功能简单,基本没人使用和维护了且安装需要依赖淘宝的diamond配置管理系统比较麻烦。 atlas(不推荐) 360开源的,属于proxy层方案,功能简单且没人维护了 sharding-jdbc(推荐,小公司) 当当开源的,属于client层方案,功能较多,社区活跃,推荐使用。 mycat(推荐,大公司) 基于cobar改造的,属于proxy层方案,社区活跃。 分库分表拆分方式 水平拆分 range来分(数据连续依据时间划分) 扩容很容易,可以依据月份写到新库中； 缺点容易产生热点问题,大量的流量都请求在最新的数据上 ​ hash分法(依据订单hash划分库) 可以平均分配没给库的数据量和请求压力； 坏处在于扩容起来比较麻烦,会有数据迁移的过程 垂直拆分 分库分表方案 停机迁移方案 双写迁移方案 在写入的时候同时写入老库和新的基于中间件的分库,启动迁移程序,不断的读取老库中的数据通过中间件写到新的分库中,在写的时候先查询一下如果不存在或者修改时间比新库中的新才写入,写完后可能数据还不一致,需要继续跑几遍才可能一致,直到老库和新库中的数据一致才算完成,随后将写老库的代码下线。 动态扩容和缩容https://my.oschina.net/u/1859679/blog/1577049 https://kefeng.wang/2018/07/22/mysql-sharding/ 分库分表后全局id的获取 myqsl自动增长列(新建一台mysql服务) 全局ID映射表 在全局 Redis 中为每张数据表创建一个 ID 的键，记录该表当前最大 ID；每次申请 ID 时，都自增 1 并返回给应用；Redis 要定期持久至全局数据库。 UUID(128位) 优点：简单，全球唯一； 缺点：存储和传输空间大，无序，性能欠佳。 COMB(组合) 组合 GUID(10字节) 和时间(6字节)，达到有序的效果，提高索引性能。 Snowflake(雪花) 算法 Snowflake 是 Twitter 开源的分布式 ID 生成算法，其结果为 long(64bit) 的数值。其特性是各节点无需协调、按时间大致有序、且整个集群各节点单不重复。 8种通讯协议对比 dubbo中文官网]]></content>
      <categories>
        <category>杂记</category>
      </categories>
      <tags>
        <tag>杂记</tag>
        <tag>记录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm内存排查]]></title>
    <url>%2F2018%2F10%2F01%2Fsenssic.github.io%2F201901%2Fjvm%E5%86%85%E5%AD%98%E6%8E%92%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[一般线上JVM问题属于比较紧急的情况,需要立即保留现场信息,并及时回复生产。 保留现场 打印堆栈信息 jstack java进程id dump堆内存 jmap -dump:format=b,file=./jvmdump java进程id 打印至少30秒的jvm垃圾回收情况 jstat -gcutil java进程id 1000 查看堆内存占用情况 jmap -histo java进程id,或jmap -histo:live java进程id 查看堆情况 jmap -heap java进程id 查询系统日志/var/log/messages 一般java进程突然消失,可以到这个里面查看信息 有事在tomcat的jvm配置时候需要添加一些额外参数,这样在系统宕机之前可以保留一些关键的信息 ​ -XX:+PrintGCDetails ​ -XX:+PrintGCDateStamps ​ -XX:+HeapDumpOnOutOfMemoryError ​ -XX:HeapDumpPath=/usr/temp/dump ​ -Xloggc:/usr/temp/dump/heap_trace.txt [确保/usr/temp目录存在] 一般问题原因 持续发生Full GC，但是系统不抛出OOM错误 堆内存溢出：java.lang.OutOfMemoryError：Java heap space 持久带溢出:java.lang.OutOfMemoryError： PermGen Space (jdk8已移除) 线程过多：java.lang.OutOfMemoryError：unable to create new native thread JAVA进程退出,一般JVM设置过大导致内存不够用也会导致,JVM一般设置为内存的65% CPU占用过高 JIT编译导致load过高 堆内存分析使用到的工具 MAT Jprofile Btrace MAT使用进阶 jstat命令详解 JVM问题分析处理手册 jmap命令详解 jvm性能调优 Linux系统日志及日志分析]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>jvm</tag>
        <tag>内存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java并发编程]]></title>
    <url>%2F2018%2F09%2F15%2Fsenssic.github.io%2F201901%2Fjava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[并发编程的挑战上下文切换​ CPU会给每个线程分配时间片用于分配给各个线程执行和占用资源,所以在多线程执行的情况下需要对执行上下文不停切换,会消耗CPU资源,所以在某些特定情况下单线程会比多线程消耗时间少。我们要尽可能的减少上下文切换。 无锁并发编程；多线程的锁竞争会引起上下文切换,处理数据时尽量避免使用锁。例如hash取模,CAS算法等。 使用最少线程；避免创建不需要的线程,不然会导致大量线程等待。 协程；单线程实现多任务调度,并支持多个任务间切换,而避免发生上下文切换。 死锁​ 锁在多线程编程中处理共享资源有很大的作用,但是在使用锁的时候极有可能在多线程环境中发生死锁,从而导致系统不可用,所以我们应避免死锁的发生,避免死锁的基本方法和注意点。 避免一个线程同时获取多个锁,线程获取多个锁资源等会导致资源处理复杂且容易与其他线程发生资源互等待 避免一个线程在锁内同时占用多个资源,尽量保证每个锁只占用一个资源。 使用定时锁或超时锁,这样当获取锁超时会自动退出锁等待释放资源。 对于数据库锁,加锁和解锁必须在一个数据库链接里,否则会出现解锁失败的情况。 资源限制​ 资源限制是指在进行并发编程时,程序的执行速度受限于计算机硬件资源或软件资源。突破资源限制方式 硬件解决方式,可以使用很多廉价的硬件组合编程集群 软件解决的方式,可以使资源进行并发的执行提高效率 java并发机制的底层实现volatile关键字​ Java编程语言允许线程访问共享变量，为了 确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获得这个变量,java内存模型确保所有线程看到这个变量的值是一致的。 ​ volatile实现原理是通过JVM在volatile变量进行写操作后JVM会向处理器发送一条lock的前缀指令,CPU指令lock指令在多核处理器会按照如下方式执行。 将当前处理器缓存行的数据写回到系统内存。 写回内存的操作会使在其他CPU内缓存了该内存地址的数据无效。(CPU缓存一致性,每个处理器探测到中线上传播的数据来检查自己缓存的值是否过期,发现自己缓存行对应的内存地址呗修改,就会将当期处理器的缓存行设置成无效状态,当处理器对这个数据进行修改操作的时候,会重新重系统内存中把数据读到处理器缓存里) synchronized关键字​ synchronized是较少进入java进行多线程同步锁处理的关键字,在JDK1.6之前直接通过锁对象实现,获取和释放锁消耗代价都比较大,之后引用了偏向锁,轻量级锁等,其性能有较大的提升。 ​ java每个对象都可以作为锁对象,synchronized对不同的地方使用有不同的锁对象。 对于普通同步方法，锁是当前实例对象。 对于静态同步方法，锁是当前类的Class对象。 对于同步方法块，锁是Synchonized括号里配置的对象。 synchronized关键字的方法和代码同步是通过Monitor对象实现的。对于代码块的同步是编译器将monitorenter插入到同步代码块开始的位置,而monitorexit插入到方法结束和异常处。JVM保证每个monitorenter必须有一个对应的monitorexit,任何synchronized锁对象都有一个monitor与之关联,线程通过对monitor对象的持有进行互斥,使用monitorenter和monitorexit进行锁的获取和释放。 原子操作的实现​ 原子操作意为不可被中断的一个或一系列操作,一般处理器是通过对缓存和总线加锁的方式实现多处理器之间的原子操作。 通过总线锁保证原子性 通过处理器提供的LOCK#信号,当处理器在总线上输出此信号,其他处理器的请求将被阻塞,该处理器可以独占共享内存。 使用缓存锁保证原子性 一般原子操作我们只需要保证对某个地址的操作是原子性的即可,但是总线锁吧CPU和内存之间的通信锁定了,其他处理器不能操作其他内存数据,开销大。使用缓存锁是如果内区域被缓存在外处理器的缓存行中,并且在lock操作期间被锁定,当执行行锁操作回写内存时不是声明LOCK#信号,而是修改内部内存地址,使用缓存一致性保证原子性。 java实现原子操作 使用循环CAS实现原子操作;利用处理器提供的CMPXCHG指令实现,循环进行CAS操作直到成功为止。CAS能基本保证java的原子操作,但是也会有很多缺点 ABA问题 循环时间长开销大 只能保证一个共享变量的原子操作 使用锁机制实现原子同步;只有获得锁的线程才能够操作锁定的内存区域。JVM锁机制有偏向锁,轻量级锁和互斥锁等。除了偏向锁,JVM实现锁的方式都用了循环 CAS,即当一个线程想进入同步块的时候使用循环CAS的方式来获取锁,当它退出同步块的时候使用循环CAS释放锁。 java内存模型​ 在并发编程中,线程之间通讯和线程之间的同步是关键问题。 ​ 线程间的通讯一般使用共享内存和消息传递。在共享内存的并发模型中,通过写-读内存中的公共状态进行隐式通讯。在消息传递的并发模型里,线程之间没有内存公共状态,必须通过显式发送消息进行通讯。 ​ 线程同步是指程序中不同线程之间操作发生相对顺序控制机制。在共享内存中,同步是显式进行的,必须指定摸个方法或代码段在线程之间互斥。在消息传递模型中,同步是隐式进行的,因为发送必须在消息的接收之前。 ​ java的并发使用的共享内存模型,所以线程通讯总是隐式进行的,而同步需要显式指定需要互斥的方法或者代码段。 java内存模型的抽象结构​ java所有实例域,静态域,和数组都存储在堆内存中,线程之间共享。而局部变量,方法定义参数,异常处理器参数不会再线程之间共享,不会有内存可见性问题。 ​ java线程之间的共享变量存储在主内存中,每个线程都有一个私有的本地内存,内存内存存储该线程读/写共享变量的副本。所以A线程和B线程如故需要通讯,需要经历类似如下流程,A线程把本地内存副本共享变量A1刷新到主内存中,线程B线程到主内存中去读线程A之前更新过的共享变量。 ​ JMM控制一个线程对共享变量的写入何时对另一个线程可见,JMM通过控制住内存与每个线程的本地内存之间的交互,为java程序员提供内存可见性保证。 指令序列的重排序​ 在程序执行时,为了提高性能,编译器和处理器有时会对执行做重排序。一般分为编译器优化重排序,指令执行重排序,内存系统重排序。其中指令和内存重排序属于处理器重排序,编译器优化属于编译器重排序。JMM对于编译器重排序使用禁止特定类型的编译器重排序,对于处理器重排序使用插入特定类型的内存屏障禁止特定类型的处理器重排序来为程序员提供一致性内存可见的保证。 内存屏障 现在处理器使用写缓冲区临时保存箱内存写入的数据,写缓冲区可以保证指令流水线持续执行,避免由于处理器停顿下来等待向内存写入数据而产生的延迟。可以批处理的方式刷新写缓冲区,以及合并写缓冲区对同一内存的多次写,减少对内存总线的占用。每个处理器上的写缓冲区仅对它所在的处理器可见。 为了保证内存可见性,java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。JMM把内存屏障指令分为4类。 happens-before 在JMM中,如果一 个操作执行的结果需要对另一个操作可见,那么这两个操作之间必须要存在happens-before关系.这里提到的两个操作既可以是在一个线程之内,也可以是在不同线程之间。一般主要的happens-befor规则有以下几种: 程序顺序规则;一个线程中的每个操作,happens-before于该线程中的任意后续操作。 监视器锁规则;对一个锁的解锁,happens-before于随后对这个锁的加锁。 volatile变量规则;对一个volatile域的写,happens-before于任意后续对这个volatile域的读。 传递性;如果A happens-before B,且B happens-before C,那么A happens-before C。 start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的 ThreadB.start()操作happens-before于线程B中的任意操作。 join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作 happens-before于线程A从ThreadB.join()操作成功返回。 happens-before规则简单易懂,避免了程序员为了理解JMM提供的内存可见性保证而去学习复杂的重排序规则以及这些规则的具体实现方法 JMM的内存可见性保证 通过对内存屏障以及happens-before的了解,JMM为程序员提供了JVM的内存可见性保证,具体可以分为如下三种: 1.单线程程序;单线程程序不会出现内存可见性问题,编译器、runtime和处理器会共同确保单线程程序的执行结果与该程序在顺序一致性模型中的执行结果相同。 2.正确同步的多线程程序;正确同步的多线程程序的执行将具有顺序一致性(程序的执行 结果与该程序在顺序一致性内存模型中的执行结果相同),JMM通过限 制编译器和处理器的重排序来为程序员提供内存可见性保证。 3.未同步/未正确同步的多线程程序;JMM为它们提供了最小安全性保障:线程执行时读取到的值,要么是之前某个线程写入的值,要么是默认值(0、null、false)。 java并发的基础线程简介线程是操作系统调度的最小单元,在一个进程里可以创建多个线程,这些线程都拥有各自的计数器,堆栈和局部变量等属性,并且能够访问共享的内存变量。处理器在这些线程上高速切换,让用户感觉这些线程在同时执行。 为什么使用多线程​ 多线程在某些特定的条件下并不一定比单线程执行效率高。但是在正确的使用多线程可以显著为程序员和用户带来好处。 更多的处理器核心;随着处理器的核心数越来越多,现代计算机更擅长并行计算,能更大效率的使用计算机处理器。 更快的响应时间;能极大的利用处理器的效率,在宏观下能并行处理多个任务线,给用户更快的响应时间。 更好的编程模型;是开发人员更加专注问题的解决,为问题简历合适的模型,而不是考虑如何将其多线程化。 线程的状态​ 在java线程的生命周期中有6种不同的状态,在给定的时刻线程只能处于其中的一个状态: NEW;初始状态,线程被构建,但是还没有调用start()方法。 RUNNABLE;运行状态,java线程将操作系统中的就绪和运行两种状态笼统的称为”运行中“ BLOCKED;阻塞状态,表示线程阻塞于锁 WAITING;等待状态,表示线程进入等待状态,进入等待状态表示当前线程需要等待其他线程做出一些特定动作(通知或中断) TIME_WAITING;超时等待状态,该状态不同于WAITING,它是可以再指定的时间自行返回的。 TERMINATED;终止状态,表示当前线程已执行完毕 java线程间的通讯 Volatile和synchronized关键字 java支持多线程同时访问一个对象或对象的成员变量,由于每个线程拥有这个变量的拷贝,所以在程序的执行过程中,一个线程锁访问的共享变量不一定是最新的。volatile变量能保证所有线程对变量访问都是最新的。即保证共享变量对所有线程的可见性,但有时我们需要控制方法或代码段的同步,这时候就需要使用synchronized关键字来修饰了,他保证在多线程在同一时刻,只有一个线程处于同步方法或同步块中,即保证了同步块访问的可见性和排他性。 等待/通知机制 一个线程A调用了对象O的wait()方法进入等待状态,另一个线程B调用了对象的notify()或者notifyAll()方法,线程A收到通知后从对象O的wait()方法返回,进而执行后续操作。上述两个线程通过对象O来完成交互,而对象上的wait()和notify()/notifyAll()的关系就如同开关信号,用来完成等待方和通知方之间的交互工作。 1）使用wait()、notify()和notifyAll()时需要先对调用对象加锁。 2）调用wait()方法后，线程状态由RUNNING变为WAITING，并将当前线程放置到对象的 等待队列。 3）notify()或notifyAll()方法调用后，等待线程依旧不会从wait()返回，需要调用notify()或 notifAll()的线程释放锁之后，等待线程才有机会从wait()返回。 4）notify()方法将等待队列中的一个等待线程从等待队列中移到同步队列中，而notifyAll() 方法则是将等待队列中所有的线程全部移到同步队列，被移动的线程状态由WAITING变为 BLOCKED。 5）从wait()方法返回的前提是获得了调用对象的锁。 管道输入/输出流 管道输入/输出流和普通的文件输入/输出流或者网络输入/输出流不同之处在于，它主要 用于线程之间的数据传输，而传输的媒介为内存。 管道输入/输出流主要包括了如下4种具体实现:PipedOutputStream、PipedInputStream、 PipedReader和PipedWriter，前两种面向字节，而后两种面向字符。 java中的锁​ 锁用来控制多个线程访问共享资源的方式,防止其数据或状态出现不可控的变化。 使用volatilejava提供了volatile关键字,在多个处理器中可以立即读到最新的值,即一个线程修改值后另一个线程立即能获取到更新后的值。 使用synchronized为了减少锁获取和释放带来的开销在JSE1.6版本锁的状态达到了四个,级别从低到高依次为 无锁状态&lt;偏向锁状态&lt;轻量级锁状态&lt;重量级锁状态随着竞争激烈程度依次递增。synchronize不支持锁的降级,这种策略是为了提高获取和释放锁的效率。 Lock接口​ Lock接口的实现基本都是 通过聚合了一个同步器(AQS)的子类来完成线程访问控制的。 队列同步器(AQS的介绍)​ AQS是JDK下提供的一套用于实现基于FIFO等待队列的阻塞锁或相关的同步组件的一个同步框架。实现原理是内部通过一个volatile的int类型成功变量表示同步状态,通过CAS进行原子的状态设置,内置的FIFO双向队列来完成获取锁线程的排队工作。 getState():获取当前同步状态。 setState(int newState):设置当前同步状态。 compareAndSetState(int expect,int update):使用CAS设置当前状态，该方法能够保证状态 设置的原子性。 重入锁​ 就是支持重进入的锁,它表示该锁能够支持一个线程对资源的重复加锁。除此之外,该锁的还支持获取锁时的公平和非公平性选择。在线程获取到锁之后能够再次获取该锁而不会被锁阻塞,重入锁实现原理: 1）线程再次获取锁;锁需要去识别获取锁的线程是否为当前占据锁的线程,如果是,则再 次成功获取。 2）锁的最终释放;线程重复n次获取了锁,随后在第n次释放该锁后,其他线程能够获取到该锁。锁的最终释放要求锁对于获取进行计数自增,计数表示当前锁被重复获取的次数,而锁被释放时,计数自减,当计数等于0时表示锁已经成功释放。 synchronized和reentrantLock等都是可重入锁。 公平与非公平锁的区别,公平性针对获取锁而言,如果一个锁是公平的,那么锁的获取顺序就应该符合请求的绝对时间顺序。 读写锁(ReentrantReadWriteLock)​ 读写锁在同一时刻可以允许多个读线程访问,但是在写线程访问时,所有的读线程和其他写线程均被阻塞。读写锁维护了一对锁,一个读锁和一个写锁,通过分离读锁和写锁,使得并发性相比一般的排他锁有了很大提升。 写锁的获取与释放 写锁是一个支持重进入的排它锁,如果当前线程已经获取了写锁,则增加写状态。如果当 前线程在获取写锁时,读锁已经被获取(读状态不为0)或者该线程不是已经获取写锁的线程, 则当前线程进入等待状态。 读锁的获取与释放 读锁是一个支持重进入的共享锁,它能够被多个线程同时获取,在没有其他写线程访问(或者写状态为0)时，读锁总会被成功地获取,而所做的也只是(线程安全的)增加读状态。如 果当前线程已经获取了读锁,则增加读状态。如果当前线程在获取读锁时,写锁已被其他线程 获取,则进入等待状态。 锁降级 锁降级指的是写锁降级成为读锁。如果当前线程拥有写锁,然后将其释放,最后再获取读锁,这种分段完成的过程不能称之为锁降级。锁降级是指把持住(当前拥有的)写锁,再获取到读锁,随后释放(先前拥有的)写锁的过程。 ​ RentrantReadWriteLock不支持锁升级(把持读锁、获取写锁,最后释放读锁的过程)。目的也是保证数据可见性,如果读锁已被多个线程获取,其中任意线程成功获取了写锁并更新了数据,则其更新对其他获取到读锁的线程是不可见的。 LockSupport工具​ 当需要阻塞或唤醒一个线程的时候,都会使用LockSupport工具类来完成相应 工作。LockSupport定义了一组的公共静态方法,这些方法提供了最基本的线程阻塞和唤醒功 能,而LockSupport也成为构建同步组件的基础工具。 Condition接口​ 任意一个Java对象,都拥有一组监视器方法(定义在java.lang.Object上),主要包括wait()、 wait(long timeout)、notify()以及notifyAll()方法,这些方法与synchronized同步关键字配合,可以 实现等待/通知模式。Condition接口也提供了类似Object的监视器方法,与Lock配合可以实现等 待/通知模式。 java并发容器和框架ConcurrentHashMap​ concurrentHashMap能在即保证并发环境下的安全又能保证高效的读写,其原理是将数据分成一段一段地存 储,然后给每一段数据配一把锁,当一个线程占用锁访问其中一个段数据的时候,其他段的数据也能被其他线程访问。 ​ ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可重 入锁(ReentrantLock)在ConcurrentHashMap里扮演锁的角色;HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组。Segment的结构和HashMap类似,是一种 数组和链表结构。一个Segment里包含一个HashEntry数组,每个HashEntry是一个链表结构的元素,每个Segment守护着一个HashEntry数组里的元素,当对HashEntry数组的数据进行修改时,必须首先获得与它对应的Segment锁。 ConcurrentLinkedQueue​ ConcurrentLinkedQueue是一个基于链接节点的无界线程安全队列,它采用先进先出的规则对节点进行排序,当我们添加一个元素的时候,它会添加到队列的尾部;当我们获取一个元素时,它会返回队列头部的元素。 阻塞队列​ 阻塞队列(BlockingQueue)是一个支持两个附加操作的队列。这两个附加的操作支持阻塞的插入和移除方法。 支持阻塞的插入方法:意思是当队列满时,队列会阻塞插入元素的线程,直到队列不 满。 支持阻塞的移除方法:意思是在队列为空时,获取元素的线程会等待队列变为非空。 阻塞队列常用于生产者和消费者的场景,生产者是向队列里添加元素的线程,消费者是从队列里取元素的线程。阻塞队列就是生产者用来存放元素、消费者用来获取元素的容器。 JDK 7提供了7个阻塞队列 ArrayBlockingQueue:一个由数组结构组成的有界阻塞队列。 LinkedBlockingQueue:一个由链表结构组成的有界阻塞队列。 PriorityBlockingQueue:一个支持优先级排序的无界阻塞队列。 DelayQueue:一个使用优先级队列实现的无界阻塞队列。 SynchronousQueue:一个不存储元素的阻塞队列。 LinkedTransferQueue:一个由链表结构组成的无界阻塞队列。 LinkedBlockingDeque:一个由链表结构组成的双向阻塞队列。 阻塞队列是使用通知模式实现。所谓通知模式,就是当生产者往满的队列里添加元素时会阻塞住生产者,当消费者消费了一个队列中的元素后,会通知生产者当前队列可用。 Fork/Join框架​ Fork/Join框架是Java 7提供的一个用于并行执行任务的框架,是一个把大任务分割成若干个小任务,最终汇总每个小任务结果后得到大任务结果的框架。 java中的原子操作类AtomicBoolean：原子更新布尔类型AtomicInteger：原子更新整型AtomicLong：原子更新长整型AtomicIntegerArray：原子更新整型数组里的元素AtomicLongArray：原子更新长整型数组里的元素AtomicReferenceArray：原子更新引用类型数组里的元素AtomicIntegerArray类主要是提供原子的方式更新数组里的整型AtomicReference：原子更新引用类型AtomicReferenceFieldUpdater：原子更新引用类型里的字段AtomicMarkableReference：原子更新带有标记位的引用类型AtomicIntegerFieldUpdater：原子更新整型的字段的更新器AtomicLongFieldUpdater：原子更新长整型字段的更新器AtomicStampedReference：原子更新带有版本号的引用类型 java中的并发工具类多线程完成的CountDownLatch​ CountDownLatch允许一个或多个线程等待其他线程完成操作。 同步屏障CyclicBarrier​ CyclicBarrier的字面意思是可循环使用(Cyclic)的屏障(Barrier)它要做的事情是,让一 组线程到达一个屏障(也可以叫同步点)时被阻塞,直到最后一个线程到达屏障时,屏障才会 开门,所有被屏障拦截的线程才会继续运行。 ​ CountDownLatch的计数器只能使用一次,而CyclicBarrier的计数器可以使用reset()方法重置。所以CyclicBarrier能处理更为复杂的业务场景。例如,如果计算发生错误,可以重置计数 器,并让线程重新执行一次。 控制并发线程数的Semaphore​ Semaphore（信号量）是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以 保证合理的使用公共资源。 线程交换数据的Exchanger​ Exchanger(交换者)是一个用于线程间协作的工具类。Exchanger用于进行线程间的数据交 换。它提供一个同步点,在这个同步点,两个线程可以交换彼此的数据。这两个线程通过 exchange方法交换数据,如果第一个线程先执行exchange()方法,它会一直等待第二个线程也 执行exchange方法,当两个线程都到达同步点时,这两个线程就可以交换数据,将本线程生产出来的数据传递给对方。 线程池线程池的处理流程如下 线程池判断核心线程池里的线程是否都在执行任务。如果不是，则创建一个新的工作 线程来执行任务。如果核心线程池里的线程都在执行任务，则进入下个流程。 线程池判断工作队列是否已经满。如果工作队列没有满，则将新提交的任务存储在这 个工作队列里。如果工作队列满了，则进入下个流程。 线程池判断线程池的线程是否都处于工作状态。如果没有，则创建一个新的工作线程 来执行任务。如果已经满了，则交给饱和策略来处理这个任务。 Executor框架Executor框架的主要接口 Executor是一个接口，它是Executor框架的基础，它将任务的提交与任务的执行分离开 ThreadPoolExecutor是线程池的核心实现类，用来执行被提交的任务。 ScheduledThreadPoolExecutor是一个实现类，可以在给定的延迟后运行命令，或者定期执 行命令ScheduledThreadPoolExecutor比Timer更灵活，功能更强大。 Future接口和实现Future接口的FutureTask类，代表异步计算的结果。 Runnable接口和Callable接口的实现类，都可以被ThreadPoolExecutor或ScheduledThreadPoolExecutor执行。 java并发编程]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>并发编程</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[哈希表_散列表]]></title>
    <url>%2F2018%2F08%2F20%2Fsenssic.github.io%2F201901%2F%E5%93%88%E5%B8%8C%E8%A1%A8-%E6%95%A3%E5%88%97%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[哈希表介绍哈希表(也称散列表,hash table),是根据键值直接访问其对应的数据存储位置的一种数据结构。若使用数组或者链表来存储元素则在比较某个元素时,数组或链表需要循环进行比较,而通过哈希表只需要计算出对应的哈希位置取出对应的值进行比较或判断在否。 其有以下几种特性: 若关键字为k,则其值存放在f(k)[散列函数]的存储位置上。 对不同的关键字可能得到同一散列地址，即k1≠k2而f(k1)=f(k2),这种现象称为冲突。 若对于关键字集合中的任一个关键字，经散列函数映象到地址集合中任何一个地址的概率是相等的，则称此类散列函数为均匀散列函数,以便减少冲突。 构造哈希函数的方法一个好的哈希函数能够提升查找效率减少哈希地址冲突带来的额外处理开销,常用的哈希函数有以下几种: 直接地址 H(key) = key 或 H(key) = a*key + b，其中a和b为常数 平方取中法 先计算出关键字值的平方，然后取平方值中间几位作为散列地址。假如有以下关键字序列{421，423，436}，平方之后的结果为{177241，178929，190096}，那么可以取中间的两位数{72，89，00}作为Hash地址。 折叠法 将关键字拆分成几部分，然后将这几部分组合在一起，以特定的方式进行转化形成Hash地址。假如知道图书的ISBN号为8903-241-23，可以将address(key)=89+03+24+12+3作为Hash地址。 除留取余法 如果知道Hash表的最大长度为m，可以取不大于m的最大质数p，然后对关键字进行取余运算，address(key)=key%p。在这里p的选取非常关键，p选择的好的话，能够最大程度地减少冲突，p一般取不大于m的最大质数。当关键字是整数时候比较好的避免冲突。 数字分析法 假设关键字是以r为基的数，并且哈希表中可能出现的关键字都是事先知道的，则可取关键字的若干数位组成哈希地址。 随机数法 选择一个随机函数，把关键字的随机函数值作为它的哈希值,通常当关键字的长度不等时用这种方法。当关键字是小数的时候比较好的避免地址冲突。 解决哈希冲突基于哈希的数据结构有着接近常量的时间即0(1)[基于数据]的时间复杂度,对于大量数据的查询效率极为高效。哈希的查找效率因数基本和哈希函数是否均匀,处理冲突的方法,哈希表的加载因子有关。 开放地址法 当发生冲突时,从当前位置向后按某种策略遍历哈希表。当发现可用的空间的时候,则插入元素。开放地址有一次探测(hs=(h(key)+i) ％ m,0 ≤ i ≤ m-1)、二次探测(hi=(h(key)+i*i) ％ m，0 ≤ i ≤ m-1)和双重哈希(hs=(h(key)+i*h1(key)) ％ m,0 ≤ i ≤ m-1)。 一次探测 探查时从地址 d 开始，首先探查 T[d]，然后依次探查 T[d+1]，…，直到 T[m-1]，此后又循环到 T[0]，T[1]，…，直到探查到 有空余地址 或者到 T[d-1]为止。 二次探测 探查时从地址 d 开始，首先探查 T[d]，然后依次探查 T[d+1^2]，T[d+2^2]，T[d+3^2],…，等，直到探查到 有空余地址 或者到 T[d-1]为止。缺点是无法探查到整个散列空间。 双重哈希 探查时从地址 d 开始，首先探查 T[d]，然后依次探查 T[d+h1(d)], T[d + 2*h1(d)]，…，等。该方法使用了两个散列函数 h(key) 和 h1(key)，故也称为双散列函数探查法。定义 h1(key) 的方法较多，但无论采用什么方法定义，都必须使 h1(key) 的值和 m 互素，才能使发生冲突的同义词地址均匀地分布在整个表中，否则可能造成同义词地址的循环计算。该方法是开放定址法中最好的方法之一。 开放定址在解决当前冲突的情况下同时可能会导致新的冲突，而开链不会有这种问题。 链地址法(又开链法) 开链的思想是哈希表中的每个元素都是一个类似链表或者其他数据结构的 head。当出现冲突时，我们就在链表后面添加元素。这也就意味着，如果某一个位置冲突过多的话，插入的时间复杂段将退化为 O(N)。 开链相比于开放定址局部性较差，在程序运行过程中可能引起操作系统的缺页中断，从而导致系统颠簸。 ​ 再哈希法 Hi=RH1（key） i=1，2，…，k 当哈希地址Hi=RH1（key）发生冲突时，再计算Hi=RH2（key）……，直到冲突不再产生。这种方法不易产生聚集，但增加了计算时间。很多语言或者工具包再哈希的内部实现是使用了两个数组，其中一个作为备用。如果当前哈希表的负载因子（元素个数/哈希表容量大小）过大或者过小时，就将数据切换到备用数组里。 建立一个公共溢出区 假设哈希函数的值域为[0,m-1],则设向量HashTable[0..m-1]为基本表，另外设立存储空间向量OverTable[0..v]为溢出表用以存储发生冲突的记录。，凡是和基本表发生冲突的元素，一律填入溢出表。 一次性哈希算法在分布式的系统中我们希望能把数据进行分布式存储,这样能极大的提升整体性能,但是需要保证相同的缓存key请求总是能被负载到同一台机器。我们可以使用简单的hash算法,对于每次访问，可以按如下算法计算其哈希值： h = Hash(key) % n 字符串到正整数的哈希映射函数。这样，如果我们将服务器数量n分别编号为0、1、2，那么就可以根据上式和key计算出服务器编号h，然后去访问。 这样做虽然能解决问题,但是存在扩展性不好的缺点,如果增加或删除一台机器势必需要哈希值得重新计算导致大量的key会被重定位到不同的服务器从而造成大量的缓存不命中。 ​ 简单来说，一致性哈希将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0 - 232-1（即哈希值是一个32位无符号整形）,整个空间按顺时针方向组织。0和232-1在零点中方向重合。将数据key使用相同的函数H计算出哈希值h，通根据h确定此数据在环上的位置，从此位置沿环顺时针“行走”，第一台遇到的服务器就是其应该定位到的服务器。一致性哈希算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。 虚拟节点​ 一致性哈希算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜问题。使得大量数据会访问到同一台机器上,为了解决这种数据倾斜问题，一致性哈希算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。数据定位算法不变，只是多了一步虚拟节点到实际节点的映射。 哈希表的实现(1) 一次性了解哈希相关概念：哈希 哈希函数 冲突解决 哈希表 聊一聊哈希表 [一致性哈希算法及其在分布式系统中的应用]]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>哈希表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式锁的常见实现]]></title>
    <url>%2F2018%2F08%2F17%2Fsenssic.github.io%2F201901%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%B8%B8%E8%A7%81%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[现在的系统部署大部分都是分布式部署的方式,对于需要使用锁的场景不能再通过使用单纯的Java Api实现。产生了基于数据库，缓存(redis,memcached,tair),和zookeeper实现的分布式锁。 对于分布式锁我们希望的理想锁的表现 在分布式环境中保证同一个临界区在同一时间只在一台机器上执行。 这把分布式锁是可重入锁[避免死锁] 可以根据业务需要变成阻塞锁 获取和释放锁性能高 基于数据库实现分布式锁基于唯一索引实现1.创建一张带唯一索引的表 12345678CREATE TABLE `blockLock` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT '主键', `block_name` varchar(64) NOT NULL DEFAULT '' COMMENT '锁定的块名称', `desc` varchar(1024) NOT NULL DEFAULT '备注信息', `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '保存数据时间，自动生成', PRIMARY KEY (`id`), UNIQUE KEY `uidx_method_name` (`block_name `) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8; 2.在想要添加锁的块代码之前插入数据,由于block_name做了唯一索引,同样块名称的操作只能有一个成功。 1insert into methodLock(method_name,desc) values (‘block_name’,‘the same block_name commit’); 3.临界代码执行完毕需要释放锁,此时只需要将block_name这条数据删除或更新即可 1delete from methodLock where method_name ='block_name' 优点: 实现方便,便于理解 缺点: 如果数据库是单点,则可靠性不能保证 没有失效时间,不会自动释放锁,一旦解锁失败会导致其他线程无法再获取到锁。 这把锁只能是非阻塞的,插入失败直接报错返回,无法自动阻塞再次尝试获取锁 这把锁是非重入锁,线程获取锁后无法再次获取此锁,因为数据库已存在唯一索引值。 对于基于数据库的锁获取和释放锁的开销相对比较大 基于数据库的排他锁在mySql的InnoDB引擎的查询语句后增加for update,这样在查询的过程中数据库会增加排他锁【注意:如果想使用查询参数要建立唯一索引,由于InnoDB 预设是Row-Level Lock，所以只有「明确」的指定主键，MySQL 才会执行Row lock (只锁住被选取的数据) ，否则MySQL 将会执行Table Lock (将整个数据表单给锁住】。 添加锁代码1234567891011121314151617181920public boolean lock()&#123; Long timeout=10000； long futureTime = System.currentTimeMillis() + timeOuts; connection.setAutoCommit(false) while(true)&#123; try&#123; result = select * from blockLock where block_name=xxx for update; if(result==null)&#123; return true; &#125; &#125;catch(Exception e)&#123; &#125; sleep(1000); if(futureTime&lt;System.currentTimeMillis())&#123; break; &#125; &#125; return false;&#125; 释放锁代码123public void unlock()&#123; connection.commit();&#125; 优点: 阻塞锁,for update语句会一直等待直到执行成功后返回结果 自动释放锁,当数据库连接断开时候会自动释放锁 缺点: 如果数据库是单点,则可靠性不能保证 对于基于数据库的锁获取和释放锁的开销相对比较大 使用不当容易变成表级锁,容易影响业务 利用事务进行加锁的时候会导致很多连接不能及时释放,导致连接池爆满 基于缓存实现分布式锁相较于数据库实现的分布式锁,基于缓存实现的分布式锁更加高效，且有很多成熟的方案,redis,memcached以及tair等都有很好的支持。 下面是基于redis实现的分布式锁 添加锁代码123456789101112private static final String LOCK_SUCCESS = "OK";private static final String SET_IF_NOT_EXIST = "NX";private static final String SET_WITH_EXPIRE_TIME = "PX";public static boolean tryGetDistributedLock(Jedis jedis, String lockKey, String requestId, int expireTime) &#123; String result = jedis.set(lockKey, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime); if (LOCK_SUCCESS.equals(result)) &#123; return true; &#125; return false;&#125; 第一个为key，我们使用key来当锁，因为key是唯一的。 第二个为value，我们传的是requestId，很多童鞋可能不明白，有key作为锁不就够了吗，为什么还要用到value？原因就是我们在上面讲到可靠性时，分布式锁要满足第四个条件解铃还须系铃人，通过给value赋值为requestId，我们就知道这把锁是哪个请求加的了，在解锁的时候就可以有依据。requestId可以使用UUID.randomUUID().toString()方法生成。 第三个为nxxx，这个参数我们填的是NX，意思是SET IF NOT EXIST，即当key不存在时，我们进行set操作；若key已经存在，则不做任何操作； 第四个为expx，这个参数我们传的是PX，意思是我们要给这个key加一个过期的设置，具体时间由第五个参数决定。 第五个为time，与第四个参数相呼应，代表key的过期时间。 ##释放锁代码: 12345678910111213private static final Long RELEASE_SUCCESS = 1L;public static boolean releaseDistributedLock(Jedis jedis, String lockKey, String requestId) &#123; //就是在eval命令执行Lua代码的时候，Lua代码将被当成一个命令去执行，并且直到eval命令执行完成，Redis才会执行其他命令。 String script = "if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end"; Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId)); if (RELEASE_SUCCESS.equals(result)) &#123; return true; &#125; return false; &#125; 首先获取锁对应的value值，检查是否与requestId相等，如果相等则删除锁（解锁）。使用Lua语言来确保上述操作是原子性。 优点： 缓存服务可以做集群提高可用性 获取锁和释放锁效率高 可以设置超时时间,超时会自动释放锁 缺点: 这是把非阻塞锁,无论成功失败会直接返回 这是把非重入锁,当一个线程获取锁后在释放锁前此线程无法再次获得该锁 失效时间平衡设置比较困难(时间短,会产生并发问题,时间长,会导致浪费的资源等待) 基于zookeeper实现分布式锁zookeeper会为客户端加锁的请求建立唯一一个瞬时有序节点,判断获取锁只需要判断此节点是否为此有序节点中序号最小的一个。当释放锁时候,只需要将这个瞬时节点删除可以。 使用curator客户端操作zookeeper 123456789101112131415161718public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; try &#123; return interProcessMutex.acquire(timeout, unit); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return true;&#125;public boolean unlock() &#123; try &#123; interProcessMutex.release(); &#125; catch (Throwable e) &#123; log.error(e.getMessage(), e); &#125; finally &#123; executorService.schedule(new Cleaner(client, path), delayTimeForClean, TimeUnit.MILLISECONDS); &#125; return true;&#125; 优点: 锁释放,当客户获取锁后突然挂掉(session连接断开),临时节点会自动删除。其他客户端可以再次获取锁 可实现阻塞锁,客户端通过在zk中创建有顺序节点,并且绑定监听,如果节点变化zk会通知客户端,客户端检查自己创建的节点是不是当前所有节点中序号最小的从而判断是否获取到锁。 可重入,客户端在创建节点时,zk会把当前客户端主机信息和线程信息写到节点中,客户端线程再次想获取锁时候和当前最小节点的数据对比一下就可以了。如果信息一样便是已获取到锁。 高可用,zk是集群部署的。 缺点: 由于需要很多判断和信息写入读取,以及分发信息,效率并没有基于缓存的高 有极低的概率会(zk有重试机制只有多次重试仍检测不到客户端心跳就会删除客户端临时节点)导致并发问题,如:当网络抖动失去客户端连接,别的客户端可能会得到分布式锁。 分布式锁的几种实现Redis 分布式锁的正确实现方式（ Java 版 ）]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>锁</tag>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java锁相关]]></title>
    <url>%2F2018%2F08%2F16%2Fsenssic.github.io%2F201901%2Fjava%E9%94%81%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[在并发系统中常常需要对某些业务资源进行加锁操作，解决一些因并发操作导致的数据不一致,以及读到脏数据问题。 加锁的目的本质上是对资源的一种操作控制,防止其数据或状态出现不可控的变化。 java中对于锁的支持使用volatilejava提供了volatile关键字,在多个处理器中可以立即读到最新的值,即一个线程修改值后另一个线程立即能获取到更新后的值。 在某些适用volatile场景的地方使用volatile控制线程变量可见性会起到很好的效果,虽然volatile不能代替synchronize(因为volatile不能提供原子操作,只是对于多线程的变量可见性),但在适用的场景下要优于synchronize执行成本,因为它不会引起线程上下文的切换和调度。 使用synchronizesynchronize通过锁机制实现同步具体锁对象有三种方式 普通方法的同步,锁是当前实力对象 静态方法的同步,锁是当前类的class对象 对于同步代码块,锁是括号内的对象 synchronize的实现原理synchronize是通过jvm执行Monitor的互斥执行和协作来实现锁的。 互斥:使用synchronize获取的对象锁来进行共享数据线程互斥 协作:通过notify/notifyAll/wait方法同步线程之间的操作 必要条件:每个Object和Class都关联了一个monitor Monitor 的工作机理 线程进入同步方法中。 为了继续执行临界区代码，线程必须获取 Monitor 锁。如果获取锁成功，将成为该监视者对象的拥有者。任一时刻内，监视者对象只属于一个活动线程（The Owner）,对于重入的synchronize关键字monitor会讲进入数自增1,所以synchronize是可重入锁 拥有监视者对象的线程可以调用 wait() 进入等待集合（Wait Set），同时释放监视锁，进入等待状态。 其他线程调用 notify() / notifyAll() 接口唤醒等待集合中的线程，这些等待的线程需要重新获取监视锁后才能执行 wait() 之后的代码。 同步方法执行完毕了，线程退出临界区，并释放监视锁。 synchronize锁机制的优化为了减少锁获取和释放带来的开销在JSE1.6版本锁的状态达到了四个,级别从低到高依次为 无锁状态&lt;偏向锁状态&lt;轻量级锁状态&lt;重量级锁状态随着竞争激烈程度依次递增。synchronize不支持锁的降级,这种策略是为了提高获取和释放锁的效率。 偏向锁-一段代码一直被同一个线程访问,那么该线程自动获取锁,此举为了降低获取锁的代价。 优点:加锁和解锁不需要额外的消耗,和非同步代码比较仅存在纳秒级别的差距。 缺点:一旦出现锁竞争会有撤销锁的消耗。 轻量级锁-当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。 优点:线程不阻塞,提高性能 缺点:如果长时间得不到锁自旋会消耗cpu 重量级锁-当锁是轻量级锁的时候,另一个线程虽然在自旋但不会一直自旋,当自旋到一定次数还没有获取到锁就会进入阻塞该锁膨胀为重量级锁,重量级锁会让其他申请的线程进入阻塞,性能降低。 优点:不会消耗cpu 缺点:线程阻塞,响应时间缓慢。 自旋状态-轻量级锁的具体实现原理,指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。 CAS(compare and swap)和AQS(AbstractQueuedSynchronizer)CAS的介绍CAS是一个原子操作,利用了处理器的CMPXCHG指令实现的,CAS操作包括三个操作数,内存位置(V),预期原值(A)和新值(B)。如果内存位置和预期原值相等则处理器会将内存位置更新为新值(B),若反之则不做任何操作。 CAS的优点在于竞争不大的情况下系统开销小,缺点是只能保证一个变量的原子操作,以及不能避免ABA问题(如果另一个线程修改V值假设原来是A，先修改成B，再修改回成A,当前线程的CAS操作无法分辨当前V值是否发生过变化)。 AQS的介绍AQS是JDK下提供的一套用于实现基于FIFO等待队列的阻塞锁或相关的同步组件的一个同步框架。 AQS的实现原理内部通过一个volatile的int类型成功变量表示同步状态 123456789101112131415161718192021222324252627282930/** * The synchronization state. * 同步状态 */private volatile int state;/** * Returns the current value of synchronization state. * 获取当前同步状态 */protected final int getState() &#123; return state;&#125;/** * Sets the value of synchronization state. * 设置当前同步状态 */protected final void setState(int newState) &#123; state = newState;&#125;/** * Atomically sets synchronization state to the given updated * value if the current state value equals the expected value. * 使用CAS设置当前状态,该方法能保证状态设置的原子性 */protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125; 内置的FIFO双向队列来完成获取锁线程的排队工作 同步器包含两个节点类型的应用，一个指向头节点，一个指向尾节点，未获取到锁的线程会创建节点线程安全（compareAndSetTail）的加入队列尾部。同步队列遵循FIFO，首节点是获取同步状态成功的节点。 未获取到锁的线程将创建一个节点，设置到尾节点 首节点的线程在释放锁时，将会唤醒后继节点。而后继节点将会在获取锁成功时将自己设置为首节点 独占式和共享式获取锁独享锁-指该锁一次只能被一个线程所持有共享锁-指该锁可被多个线程所持有 独占锁(ReentrantLock) ​ 每个节点自旋观察自己的前一节点是不是Header节点，如果是，就去尝试获取锁 ​ 独占式锁获取流程 ​ 共享锁(CountDownLatch) ​ 共享式与独占式的区别 ​ 共享锁获取流程 Java中的锁 (原理、锁优化、CAS、AQS)Java中的锁分类]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[你好,世界]]></title>
    <url>%2F2018%2F08%2F09%2Fsenssic.github.io%2F%E4%BD%A0%E5%A5%BD%2C%E4%B8%96%E7%95%8C%2F</url>
    <content type="text"><![CDATA[你好,世界 你好,世界！不要在生活中迷失！ –2018年08月07日01:38:41]]></content>
      <categories>
        <category>生活百味</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>杂项</tag>
        <tag>感悟</tag>
      </tags>
  </entry>
</search>
